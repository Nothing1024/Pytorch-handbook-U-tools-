{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取HTML：带基础JS版本\n",
    "url = \"https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\"\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.105 Safari/537.36'}\n",
    "try:\n",
    "    r = requests.get(url, headers=header)\n",
    "    r.raise_for_status()\n",
    "    r.encoding = r.apparent_encoding\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # 遍历才能删除\n",
    "    for i in soup.find_all([\"nav\",\"footer\"]): # 主标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(id=[\"header-holder\", \"pytorch-page-level-bar\",\"pytorch-page-level-bar\",\"pytorch-content-right\",\"docs-tutorials-resources\"]): # id标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(class_=[\"table-of-contents-link-wrapper\",\"cookie-banner-wrapper\",\"mobile-main-menu\"]): # class标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(\"img\"): # img标签 删除谷歌指数标签\n",
    "        if type(eval(i['height'])) == int and int(i['height']) < 2:\n",
    "            i.decompose()\n",
    "    for i in soup.find_all(\"script\"): # script标签\n",
    "        if i.has_attr('src') and i['src'] in [\n",
    "            \"../_static/underscore.js\",\n",
    "            \"../_static/doctools.js\",\n",
    "            \"../_static/js/vendor/popper.min.js\",\n",
    "            \"https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js\",\n",
    "            \"https://www.googletagmanager.com/gtag/js?id=UA-117752657-2\",\n",
    "\n",
    "            \"_static/underscore.js\",\n",
    "            \"_static/doctools.js\",\n",
    "\n",
    "            \"_static/js/modernizr.min.js\",\n",
    "            \"_static/js/vendor/popper.min.js\"\n",
    "        ] or len(i.attrs) == 0 or (i.has_attr(\"script\") and len(str(i[\"script\"])) == 0):\n",
    "            i.decompose()\n",
    "    for i in soup.find_all(\"link\"): # link标签\n",
    "        if i['rel'][0] in ['next', 'prev', 'index', 'search']:\n",
    "            i.decompose()\n",
    "    for i in soup(text = lambda text: isinstance(text,Comment)): # 遍历才能删除\n",
    "        i.extract()\n",
    "    f = open(\"q.html\", \"w\", encoding='utf-8')\n",
    "    f.write(str(soup.prettify()))\n",
    "except Exception as e:\n",
    "    print(\"爬取失败\",e.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取HTML：最精简版本，无CSS，Utools用\n",
    "url = \"https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\"\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.105 Safari/537.36'}\n",
    "try:\n",
    "    r = requests.get(url, headers=header)\n",
    "    r.raise_for_status()\n",
    "    r.encoding = r.apparent_encoding\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # 遍历才能删除\n",
    "    for i in soup.find_all([\"nav\",\"footer\"]): # 主标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(id=[\"header-holder\", \"pytorch-page-level-bar\",\"pytorch-page-level-bar\",\"pytorch-content-right\",\"docs-tutorials-resources\"]): # id标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(class_=[\"table-of-contents-link-wrapper\",\"cookie-banner-wrapper\",\"mobile-main-menu\"]): # class标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(\"img\"): # img标签 删除谷歌指数标签\n",
    "        if type(eval(i['height'])) == int and int(i['height']) < 2:\n",
    "            i.decompose()\n",
    "    for i in soup.find_all(\"script\"): # script标签\n",
    "        i.decompose()\n",
    "    for i in soup.find_all(\"link\"): # link标签\n",
    "        i.decompose()\n",
    "    for i in soup(text = lambda text: isinstance(text,Comment)): # 遍历才能删除\n",
    "        i.extract()\n",
    "    f = open(\"q.html\", \"w\", encoding='utf-8')\n",
    "    f.write(str(soup.prettify()))\n",
    "except Exception as e:\n",
    "    print(\"爬取失败\",e.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 侧边栏获取地址\n",
    "def get_category_list():\n",
    "    url = \"https://pytorch.org/docs/stable/torch.html\"\n",
    "    header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.105 Safari/537.36'}\n",
    "    default_str = \"https://pytorch.org/docs/stable/\"\n",
    "    category_list = []\n",
    "    category_list.append(default_str+\"torch.html\")\n",
    "    try:\n",
    "        r = requests.get(url, headers=header)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        for i in soup.find_all(\"ul\"):\n",
    "            if i.has_attr(\"class\") and i[\"class\"][0] == \"current\":\n",
    "                for j in i.find_all(\"li\"):\n",
    "                    if j.a.has_attr(\"href\") and j.a[\"href\"] != \"#\":\n",
    "                        category_list.append(default_str+j.a[\"href\"])\n",
    "        category_list.pop()\n",
    "        category_list = list(map(lambda x:x.replace(\"https://pytorch.org/docs/\", \"\"), category_list))\n",
    "        return category_list\n",
    "        # # print(category_list)\n",
    "        # for i in category_list:\n",
    "        #     print(i)\n",
    "    except Exception as e:\n",
    "        print(\"爬取失败\",e.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_category_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_HTML(url):\n",
    "    # 提取HTML：最精简版本，无CSS，Utools用\n",
    "    header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.105 Safari/537.36'}\n",
    "    try:\n",
    "        r = requests.get(url, headers=header)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        # 遍历才能删除\n",
    "        for i in soup.find_all([\"nav\",\"footer\"]): # 主标签\n",
    "            i.decompose()\n",
    "        for i in soup.find_all(id=[\"header-holder\", \"pytorch-page-level-bar\",\"pytorch-page-level-bar\",\"pytorch-content-right\",\"docs-tutorials-resources\"]): # id标签\n",
    "            i.decompose()\n",
    "        for i in soup.find_all(class_=[\"table-of-contents-link-wrapper\",\"cookie-banner-wrapper\",\"mobile-main-menu\"]): # class标签\n",
    "            i.decompose()\n",
    "        for i in soup.find_all(\"img\"): # img标签 删除谷歌指数标签\n",
    "            if i.has_attr('height') and type(eval(i['height'])) == int and int(i['height']) < 2:\n",
    "                i.decompose()\n",
    "        for i in soup.find_all(\"script\"): # script标签\n",
    "            i.decompose()\n",
    "        for i in soup.find_all(\"link\"): # link标签\n",
    "            i.decompose()\n",
    "        for i in soup(\"text\"): # 遍历才能删除\n",
    "            if isinstance(i,Comment):\n",
    "                i.extract()\n",
    "        url = url.replace(\"https://pytorch.org/docs/\", \"\")\n",
    "        f = open(url , \"w+\", encoding='utf-8')\n",
    "        f.write(str(soup.prettify()))\n",
    "    except Exception as e:\n",
    "        print(\"爬取失败\",e.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 单页获取二级链接内容\n",
    "def getJsonFormat(category):\n",
    "    default_url = \"https://pytorch.org/docs/\"\n",
    "    import re\n",
    "    temp_list = [] # 标题\n",
    "    temp_url_list = [] # 标题对应URL\n",
    "    # this_url = 'stable/distributed.elastic.html'\n",
    "    this_url = category\n",
    "    father = \".\" + this_url.split(\"/\")[-1].replace(\".html\" ,\"\")\n",
    "    if father == \".torch\":\n",
    "        father = \"torch\"\n",
    "    else:\n",
    "        father = \"torch\" + father\n",
    "\n",
    "    with open(this_url,encoding='utf-8',buffering=-1) as url_content:\n",
    "        try:\n",
    "            soup = BeautifulSoup(url_content.read(), 'html.parser')\n",
    "            # 检测2列表格内容\n",
    "            for i in soup.find_all(\"tr\"):\n",
    "                if len(i.find_all(\"td\")) != 2: # 只检测2列表格\n",
    "                    continue\n",
    "                temp = i.find_all(\"td\")[0]\n",
    "                for temp in temp.find_all(\"a\"):\n",
    "                    temp[\"href\"] = \"stable/\" + temp[\"href\"]\n",
    "                    if temp.has_attr(\"title\"):\n",
    "                        temp_list.append(\n",
    "                            {\"name\":temp[\"title\"],\n",
    "                            \"type\": father,\n",
    "                            \"path\":temp[\"href\"],\n",
    "                            \"desc\":re.sub(r\"\\s+\", \" \", i.find_all(\"td\")[1].text.strip().replace(\"\\n\", \"\").replace(\" .\", \"\").replace(\" ,\", \"\"))}\n",
    "                            )\n",
    "                    else:\n",
    "                        temp_list.append(\n",
    "                            {\"name\":temp[\"href\"].split(\".html\")[0],\n",
    "                            \"type\": \"torch\" + father,\n",
    "                            \"path\":temp[\"href\"],\n",
    "                            \"desc\":re.sub(r\"\\s+\", \" \", i.find_all(\"td\")[1].text.strip().replace(\"\\n\", \"\").replace(\" .\", \"\").replace(\" ,\", \"\"))}\n",
    "                            )\n",
    "                    temp_url_list.append(default_url + temp[\"href\"]) #单页获取，不进行dl处理\n",
    "            # 检测非表格内容，即class td+id号内容\n",
    "            for i in soup.find_all(\"dl\"):\n",
    "                if i.has_attr(\"class\") and len(i[\"class\"]) == 2 and i[\"class\"][0] == \"py\" and i[\"class\"][1] in [\"function\", \"class\"] :\n",
    "                    temp_list.append(\n",
    "                        {\"name\":i.dt[\"id\"],\n",
    "                        \"type\": \"torch\" + father,\n",
    "                        \"path\":this_url+\"#\"+i.dt[\"id\"],\n",
    "                        \"desc\":re.sub(r\"\\s+\", \" \", i.dd.text.strip().replace(\"\\n\", \"\").replace(\" .\", \"\").replace(\" ,\", \"\"))\n",
    "                          .split(\".\")[0] + \".\"} # 只截取第一句话\n",
    "                        )\n",
    "            # 判断如果上面都不符合，则判断疑似纯文章，后期考虑是否也进行特殊处理\n",
    "            # print(temp_list)\n",
    "            # print(len(temp_list))\n",
    "            # print(temp_url_list[:10])\n",
    "            # print(len(temp_url_list))\n",
    "            return {\n",
    "                \"temp_list\":temp_list,\n",
    "                \"temp_url_list\":temp_url_list\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(\"爬取失败\",e.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "getJsonFormat(\"stable/torch.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "default_url = \"https://pytorch.org/docs/\"\n",
    "json_dict = []\n",
    "temp_list = []\n",
    "temp_url_list = []\n",
    "# TODO 先获取侧边栏内容\n",
    "category_list = get_category_list()\n",
    "# TODO 获取单主页地址  + 添加元素\n",
    "for i in category_list[:-2]: # 一级目录链接开始循环 获取网页 + 加载信息\n",
    "    extract_HTML(default_url + i)\n",
    "    json_dict.append({\n",
    "        \"name\": i.replace(\"stable/\",\"\").replace(\".html\",\"\"),\n",
    "        \"type\": \"\",\n",
    "        \"path\": i,\n",
    "        \"desc\": \"\"\n",
    "    })\n",
    "    # TODO 获取二级地址对应元素\n",
    "    tmp_dict = getJsonFormat(i)\n",
    "    # print(tmp_dict)\n",
    "    # TODO 拼接\n",
    "    if tmp_dict['temp_list']:\n",
    "        # print(tmp_dict['temp_list'])\n",
    "        # print(i+\" 's temp_list:\"+str(len(tmp_dict['temp_list'])))\n",
    "        temp_list.extend(tmp_dict['temp_list'])\n",
    "    if tmp_dict['temp_url_list']:\n",
    "        # print(i+\" 's temp_url_list:\"+str(len(tmp_dict['temp_url_list'])))\n",
    "        temp_url_list.extend(tmp_dict['temp_url_list'])\n",
    "# TODO 二级地址全部开始爬\n",
    "for i in temp_url_list:\n",
    "    if \"#\" in i:\n",
    "        extract_HTML(i.split(\"#\")[0])\n",
    "\n",
    "json_str = json.dumps(temp_list)\n",
    "with open('pytorch.json', 'w+') as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "# Named Tensors id号问题\n",
    "# print(len(temp_list))\n",
    "# print(len(temp_url_list))\n",
    "# print(temp_list)\n",
    "# print(temp_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_category_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 单个网址处理dt元素\n",
    "import re\n",
    "\n",
    "temp_list = [] # 标题\n",
    "temp_url_list = [] # 标题对应URL\n",
    "\n",
    "this_url = 'stable/distributed.html'\n",
    "this_type = 'torch.distributed'\n",
    "father = \".distributed\"\n",
    "with open(this_url,encoding='utf-8',buffering=-1) as fin:\n",
    "    try:\n",
    "        soup = BeautifulSoup(fin.read(), 'html.parser')\n",
    "        for i in soup.find_all(\"dl\"):\n",
    "            if i.has_attr(\"class\") and len(i[\"class\"]) == 2 and i[\"class\"][0] == \"py\" and i[\"class\"][1] in [\"function\", \"class\"] :\n",
    "                temp_list.append(\n",
    "                    {\"name\":i.dt[\"id\"],\n",
    "                    \"type\": \"torch\" + father,\n",
    "                    \"path\":this_url+\"#\"+i.dt[\"id\"],\n",
    "                    \"desc\":re.sub(r\"\\s+\", \" \", i.dd.text.strip().replace(\"\\n\", \"\").replace(\" .\", \"\").replace(\" ,\", \"\"))\n",
    "                      .split(\".\")[0] + \".\"} # 只截取第一句话\n",
    "                    )\n",
    "        print(temp_list)\n",
    "        print(len(temp_list))\n",
    "\n",
    "        # print(soup.find_all(\"dt\")[0].next_sibling)\n",
    "        # TODO 判断如果上面都不符合，则判断疑似纯文章，获取超链接\n",
    "        # TODO 合并+去重\n",
    "        # print(temp_list)\n",
    "        # print(len(temp_list))\n",
    "        # print(temp_url_list[:10])\n",
    "        # print(len(temp_url_list))\n",
    "    except Exception as e:\n",
    "        print(\"爬取失败\",e.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 单页处理二列表格元素\n",
    "import re\n",
    "\n",
    "temp_list = [] # 标题\n",
    "temp_url_list = [] # 标题对应URL\n",
    "\n",
    "father = \"torch\"\n",
    "with open('stable/torch.html',encoding='utf-8',buffering=-1) as fin:\n",
    "    try:\n",
    "        soup = BeautifulSoup(fin.read(), 'html.parser')\n",
    "        for i in soup.find_all(\"tr\"):\n",
    "            add_flag = False\n",
    "            temp = i.find_all(\"td\")[0]\n",
    "            for temp in temp.find_all(\"a\"):\n",
    "                temp_list.append(\n",
    "                    {\"name\":temp[\"title\"],\n",
    "                    \"type\": \"torch\",\n",
    "                    \"path\":temp[\"href\"],\n",
    "                    \"desc\":re.sub(r\"\\s+\", \" \", i.find_all(\"td\")[1].text.strip().replace(\"\\n\", \"\").replace(\" .\", \"\").replace(\" ,\", \"\"))\n",
    "                        .split(\".\")[0] + \".\"} # 只截取第一句话\n",
    "                    )\n",
    "                temp_url_list.append(default_str + temp[\"href\"])\n",
    "        print(temp_list)\n",
    "        print(len(temp_list))\n",
    "        print(temp_url_list[:10])\n",
    "        print(len(temp_url_list))\n",
    "    except Exception as e:\n",
    "        print(\"爬取失败\",e.__str__())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c457982880702647536a32f860218fba4749b161f3b740b493c4eace7bd8e3e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
