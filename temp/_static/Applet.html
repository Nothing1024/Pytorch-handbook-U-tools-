<!DOCTYPE html>
<html class="no-js" lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   Module — PyTorch 1.10 documentation
  </title>
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="module">
         <h1>
          Module
          <a class="headerlink" href="#module" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py class">
          <dt id="torch.nn.Module">
           <em class="property">
            <span class="pre">
             class
            </span>
           </em>
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.nn.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             Module
            </span>
           </code>
           <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module">
            <span class="viewcode-link">
             <span class="pre">
              [source]
             </span>
            </span>
           </a>
           <a class="headerlink" href="#torch.nn.Module" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Base class for all neural network modules.
           </p>
           <p>
            Your models should also subclass this class.
           </p>
           <p>
            Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:
           </p>
           <div class="highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre>
            </div>
           </div>
           <p>
            Submodules assigned in this way will be registered, and will have their
parameters converted too when you call
            <a class="reference internal" href="#torch.nn.Module.to" title="torch.nn.Module.to">
             <code class="xref py py-meth docutils literal notranslate">
              <span class="pre">
               to()
              </span>
             </code>
            </a>
            , etc.
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Variables
            </dt>
            <dd class="field-odd">
             <p>
              <strong>
               training
              </strong>
              (
              <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
               <em>
                bool
               </em>
              </a>
              ) – Boolean represents whether this module is in training or
evaluation mode.
             </p>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.add_module">
             <code class="sig-name descname">
              <span class="pre">
               add_module
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                name
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                module
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.add_module">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.add_module" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Adds a child module to the current module.
             </p>
             <p>
              The module can be accessed as an attribute using the given name.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   name
                  </strong>
                  (
                  <em>
                   string
                  </em>
                  ) – name of the child module. The child module can be
accessed from this module using the given name
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   module
                  </strong>
                  (
                  <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                   <em>
                    Module
                   </em>
                  </a>
                  ) – child module to be added to the module.
                 </p>
                </li>
               </ul>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.apply">
             <code class="sig-name descname">
              <span class="pre">
               apply
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                fn
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.apply">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.apply" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Applies
              <code class="docutils literal notranslate">
               <span class="pre">
                fn
               </span>
              </code>
              recursively to every submodule (as returned by
              <code class="docutils literal notranslate">
               <span class="pre">
                .children()
               </span>
              </code>
              )
as well as self. Typical use includes initializing the parameters of a model
(see also
              <a class="reference internal" href="../nn.init.html#nn-init-doc">
               <span class="std std-ref">
                torch.nn.init
               </span>
              </a>
              ).
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 fn
                </strong>
                (
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 <code class="xref py py-class docutils literal notranslate">
                  <span class="pre">
                   Module
                  </span>
                 </code>
                </a>
                -&gt; None) – function to be applied to each submodule
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 1.,  1.],</span>
<span class="go">        [ 1.,  1.]])</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 1.,  1.],</span>
<span class="go">        [ 1.,  1.]])</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.bfloat16">
             <code class="sig-name descname">
              <span class="pre">
               bfloat16
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.bfloat16">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.bfloat16" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Casts all floating point parameters and buffers to
              <code class="docutils literal notranslate">
               <span class="pre">
                bfloat16
               </span>
              </code>
              datatype.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                self
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.buffers">
             <code class="sig-name descname">
              <span class="pre">
               buffers
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                recurse
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.buffers">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.buffers" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over module buffers.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 recurse
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                ) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.
               </p>
              </dd>
              <dt class="field-even">
               Yields
              </dt>
              <dd class="field-even">
               <p>
                <em>
                 torch.Tensor
                </em>
                – module buffer
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L,)</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L, 1L, 5L, 5L)</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.children">
             <code class="sig-name descname">
              <span class="pre">
               children
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.children">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.children" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over immediate children modules.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Yields
              </dt>
              <dd class="field-odd">
               <p>
                <em>
                 Module
                </em>
                – a child module
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.cpu">
             <code class="sig-name descname">
              <span class="pre">
               cpu
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.cpu">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.cpu" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Moves all model parameters and buffers to the CPU.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                self
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.cuda">
             <code class="sig-name descname">
              <span class="pre">
               cuda
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                device
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                None
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.cuda">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.cuda" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Moves all model parameters and buffers to the GPU.
             </p>
             <p>
              This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 device
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                 <em>
                  int
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – if specified, all parameters will be
copied to that device
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.double">
             <code class="sig-name descname">
              <span class="pre">
               double
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.double">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.double" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Casts all floating point parameters and buffers to
              <code class="docutils literal notranslate">
               <span class="pre">
                double
               </span>
              </code>
              datatype.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                self
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="torch.nn.Module.dump_patches">
             <code class="sig-name descname">
              <span class="pre">
               dump_patches
              </span>
             </code>
             <em class="property">
              <span class="pre">
               :
              </span>
              <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
               <span class="pre">
                bool
               </span>
              </a>
             </em>
             <em class="property">
              <span class="pre">
               =
              </span>
              <span class="pre">
               False
              </span>
             </em>
             <a class="headerlink" href="#torch.nn.Module.dump_patches" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              This allows better BC support for
              <a class="reference internal" href="#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 load_state_dict()
                </span>
               </code>
              </a>
              . In
              <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 state_dict()
                </span>
               </code>
              </a>
              , the version number will be saved as in the attribute
              <cite>
               _metadata
              </cite>
              of the returned state dict, and thus pickled.
              <cite>
               _metadata
              </cite>
              is a
dictionary with keys that follow the naming convention of state dict. See
              <code class="docutils literal notranslate">
               <span class="pre">
                _load_from_state_dict
               </span>
              </code>
              on how to use this information in loading.
             </p>
             <p>
              If new parameters/buffers are added/removed from a module, this number shall
be bumped, and the module’s
              <cite>
               _load_from_state_dict
              </cite>
              method can compare the
version number and do appropriate changes if the state dict is from before
the change.
             </p>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.eval">
             <code class="sig-name descname">
              <span class="pre">
               eval
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.eval">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.eval" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Sets the module in evaluation mode.
             </p>
             <p>
              This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g.
              <a class="reference internal" href="torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout">
               <code class="xref py py-class docutils literal notranslate">
                <span class="pre">
                 Dropout
                </span>
               </code>
              </a>
              ,
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                BatchNorm
               </span>
              </code>
              ,
etc.
             </p>
             <p>
              This is equivalent with
              <a class="reference internal" href="#torch.nn.Module.train" title="torch.nn.Module.train">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 self.train(False)
                </span>
               </code>
              </a>
              .
             </p>
             <p>
              See
              <a class="reference internal" href="../notes/autograd.html#locally-disable-grad-doc">
               <span class="std std-ref">
                Locally disabling gradient computation
               </span>
              </a>
              for a comparison between
              <cite>
               .eval()
              </cite>
              and several similar mechanisms that may be confused with it.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                self
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.extra_repr">
             <code class="sig-name descname">
              <span class="pre">
               extra_repr
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.extra_repr">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.extra_repr" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Set the extra representation of the module
             </p>
             <p>
              To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.
             </p>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.float">
             <code class="sig-name descname">
              <span class="pre">
               float
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.float">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.float" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Casts all floating point parameters and buffers to
              <code class="docutils literal notranslate">
               <span class="pre">
                float
               </span>
              </code>
              datatype.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                self
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.forward">
             <code class="sig-name descname">
              <span class="pre">
               forward
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="o">
               <span class="pre">
                *
               </span>
              </span>
              <span class="n">
               <span class="pre">
                input
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="headerlink" href="#torch.nn.Module.forward" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Defines the computation performed at every call.
             </p>
             <p>
              Should be overridden by all subclasses.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               Although the recipe for forward pass needs to be defined within
this function, one should call the
               <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  Module
                 </span>
                </code>
               </a>
               instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
              </p>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.get_buffer">
             <code class="sig-name descname">
              <span class="pre">
               get_buffer
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                target
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.get_buffer">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.get_buffer" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns the buffer given by
              <code class="docutils literal notranslate">
               <span class="pre">
                target
               </span>
              </code>
              if it exists,
otherwise throws an error.
             </p>
             <p>
              See the docstring for
              <code class="docutils literal notranslate">
               <span class="pre">
                get_submodule
               </span>
              </code>
              for a more detailed
explanation of this method’s functionality as well as how to
correctly specify
              <code class="docutils literal notranslate">
               <span class="pre">
                target
               </span>
              </code>
              .
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 target
                </strong>
                – The fully-qualified string name of the buffer
to look for. (See
                <code class="docutils literal notranslate">
                 <span class="pre">
                  get_submodule
                 </span>
                </code>
                for how to specify a
fully-qualified string.)
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                The buffer referenced by
                <code class="docutils literal notranslate">
                 <span class="pre">
                  target
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
                 torch.Tensor
                </a>
               </p>
              </dd>
              <dt class="field-even">
               Raises
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.10)">
                 <strong>
                  AttributeError
                 </strong>
                </a>
                – If the target string references an invalid
    path or resolves to something that is not a
    buffer
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.get_extra_state">
             <code class="sig-name descname">
              <span class="pre">
               get_extra_state
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.get_extra_state">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.get_extra_state" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding
              <a class="reference internal" href="#torch.nn.Module.set_extra_state" title="torch.nn.Module.set_extra_state">
               <code class="xref py py-func docutils literal notranslate">
                <span class="pre">
                 set_extra_state()
                </span>
               </code>
              </a>
              for your module
if you need to store extra state. This function is called when building the
module’s
              <cite>
               state_dict()
              </cite>
              .
             </p>
             <p>
              Note that extra state should be pickleable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                Any extra state to store in the module’s state_dict
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.10)">
                 object
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.get_parameter">
             <code class="sig-name descname">
              <span class="pre">
               get_parameter
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                target
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.get_parameter">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.get_parameter" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns the parameter given by
              <code class="docutils literal notranslate">
               <span class="pre">
                target
               </span>
              </code>
              if it exists,
otherwise throws an error.
             </p>
             <p>
              See the docstring for
              <code class="docutils literal notranslate">
               <span class="pre">
                get_submodule
               </span>
              </code>
              for a more detailed
explanation of this method’s functionality as well as how to
correctly specify
              <code class="docutils literal notranslate">
               <span class="pre">
                target
               </span>
              </code>
              .
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 target
                </strong>
                – The fully-qualified string name of the Parameter
to look for. (See
                <code class="docutils literal notranslate">
                 <span class="pre">
                  get_submodule
                 </span>
                </code>
                for how to specify a
fully-qualified string.)
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                The Parameter referenced by
                <code class="docutils literal notranslate">
                 <span class="pre">
                  target
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                torch.nn.Parameter
               </p>
              </dd>
              <dt class="field-even">
               Raises
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.10)">
                 <strong>
                  AttributeError
                 </strong>
                </a>
                – If the target string references an invalid
    path or resolves to something that is not an
                <code class="docutils literal notranslate">
                 <span class="pre">
                  nn.Parameter
                 </span>
                </code>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.get_submodule">
             <code class="sig-name descname">
              <span class="pre">
               get_submodule
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                target
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.get_submodule">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.get_submodule" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns the submodule given by
              <code class="docutils literal notranslate">
               <span class="pre">
                target
               </span>
              </code>
              if it exists,
otherwise throws an error.
             </p>
             <p>
              For example, let’s say you have an
              <code class="docutils literal notranslate">
               <span class="pre">
                nn.Module
               </span>
              </code>
              <code class="docutils literal notranslate">
               <span class="pre">
                A
               </span>
              </code>
              that
looks like this:
             </p>
             <p>
              (The diagram shows an
              <code class="docutils literal notranslate">
               <span class="pre">
                nn.Module
               </span>
              </code>
              <code class="docutils literal notranslate">
               <span class="pre">
                A
               </span>
              </code>
              .
              <code class="docutils literal notranslate">
               <span class="pre">
                A
               </span>
              </code>
              has a nested
submodule
              <code class="docutils literal notranslate">
               <span class="pre">
                net_b
               </span>
              </code>
              , which itself has two submodules
              <code class="docutils literal notranslate">
               <span class="pre">
                net_c
               </span>
              </code>
              and
              <code class="docutils literal notranslate">
               <span class="pre">
                linear
               </span>
              </code>
              .
              <code class="docutils literal notranslate">
               <span class="pre">
                net_c
               </span>
              </code>
              then has a submodule
              <code class="docutils literal notranslate">
               <span class="pre">
                conv
               </span>
              </code>
              .)
             </p>
             <p>
              To check whether or not we have the
              <code class="docutils literal notranslate">
               <span class="pre">
                linear
               </span>
              </code>
              submodule, we
would call
              <code class="docutils literal notranslate">
               <span class="pre">
                get_submodule("net_b.linear")
               </span>
              </code>
              . To check whether
we have the
              <code class="docutils literal notranslate">
               <span class="pre">
                conv
               </span>
              </code>
              submodule, we would call
              <code class="docutils literal notranslate">
               <span class="pre">
                get_submodule("net_b.net_c.conv")
               </span>
              </code>
              .
             </p>
             <p>
              The runtime of
              <code class="docutils literal notranslate">
               <span class="pre">
                get_submodule
               </span>
              </code>
              is bounded by the degree
of module nesting in
              <code class="docutils literal notranslate">
               <span class="pre">
                target
               </span>
              </code>
              . A query against
              <code class="docutils literal notranslate">
               <span class="pre">
                named_modules
               </span>
              </code>
              achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists,
              <code class="docutils literal notranslate">
               <span class="pre">
                get_submodule
               </span>
              </code>
              should always be
used.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 target
                </strong>
                – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                The submodule referenced by
                <code class="docutils literal notranslate">
                 <span class="pre">
                  target
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 torch.nn.Module
                </a>
               </p>
              </dd>
              <dt class="field-even">
               Raises
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.10)">
                 <strong>
                  AttributeError
                 </strong>
                </a>
                – If the target string references an invalid
    path or resolves to something that is not an
                <code class="docutils literal notranslate">
                 <span class="pre">
                  nn.Module
                 </span>
                </code>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.half">
             <code class="sig-name descname">
              <span class="pre">
               half
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.half">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.half" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Casts all floating point parameters and buffers to
              <code class="docutils literal notranslate">
               <span class="pre">
                half
               </span>
              </code>
              datatype.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                self
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.load_state_dict">
             <code class="sig-name descname">
              <span class="pre">
               load_state_dict
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                state_dict
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                strict
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.load_state_dict">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.load_state_dict" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Copies parameters and buffers from
              <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 state_dict
                </span>
               </code>
              </a>
              into
this module and its descendants. If
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                strict
               </span>
              </code>
              is
              <code class="docutils literal notranslate">
               <span class="pre">
                True
               </span>
              </code>
              , then
the keys of
              <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 state_dict
                </span>
               </code>
              </a>
              must exactly match the keys returned
by this module’s
              <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 state_dict()
                </span>
               </code>
              </a>
              function.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   state_dict
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.10)">
                   <em>
                    dict
                   </em>
                  </a>
                  ) – a dict containing parameters and
persistent buffers.
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   strict
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                   <em>
                    bool
                   </em>
                  </a>
                  <em>
                   ,
                  </em>
                  <em>
                   optional
                  </em>
                  ) – whether to strictly enforce that the keys
in
                  <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
                   <code class="xref py py-attr docutils literal notranslate">
                    <span class="pre">
                     state_dict
                    </span>
                   </code>
                  </a>
                  match the keys returned by this module’s
                  <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
                   <code class="xref py py-meth docutils literal notranslate">
                    <span class="pre">
                     state_dict()
                    </span>
                   </code>
                  </a>
                  function. Default:
                  <code class="docutils literal notranslate">
                   <span class="pre">
                    True
                   </span>
                  </code>
                 </p>
                </li>
               </ul>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                <ul class="simple">
                 <li>
                  <p>
                   <strong>
                    missing_keys
                   </strong>
                   is a list of str containing the missing keys
                  </p>
                 </li>
                 <li>
                  <p>
                   <strong>
                    unexpected_keys
                   </strong>
                   is a list of str containing the unexpected keys
                  </p>
                 </li>
                </ul>
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <code class="docutils literal notranslate">
                 <span class="pre">
                  NamedTuple
                 </span>
                </code>
                with
                <code class="docutils literal notranslate">
                 <span class="pre">
                  missing_keys
                 </span>
                </code>
                and
                <code class="docutils literal notranslate">
                 <span class="pre">
                  unexpected_keys
                 </span>
                </code>
                fields
               </p>
              </dd>
             </dl>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               If a parameter or buffer is registered as
               <code class="docutils literal notranslate">
                <span class="pre">
                 None
                </span>
               </code>
               and its corresponding key
exists in
               <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
                <code class="xref py py-attr docutils literal notranslate">
                 <span class="pre">
                  state_dict
                 </span>
                </code>
               </a>
               ,
               <a class="reference internal" href="#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict">
                <code class="xref py py-meth docutils literal notranslate">
                 <span class="pre">
                  load_state_dict()
                 </span>
                </code>
               </a>
               will raise a
               <code class="docutils literal notranslate">
                <span class="pre">
                 RuntimeError
                </span>
               </code>
               .
              </p>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.modules">
             <code class="sig-name descname">
              <span class="pre">
               modules
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.modules">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.modules" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over all modules in the network.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Yields
              </dt>
              <dd class="field-odd">
               <p>
                <em>
                 Module
                </em>
                – a module in the network
               </p>
              </dd>
             </dl>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               Duplicate modules are returned only once. In the following
example,
               <code class="docutils literal notranslate">
                <span class="pre">
                 l
                </span>
               </code>
               will be returned only once.
              </p>
             </div>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="go">        print(idx, '-&gt;', m)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.named_buffers">
             <code class="sig-name descname">
              <span class="pre">
               named_buffers
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                prefix
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                ''
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                recurse
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.named_buffers">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.named_buffers" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   prefix
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)">
                   <em>
                    str
                   </em>
                  </a>
                  ) – prefix to prepend to all buffer names.
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   recurse
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                   <em>
                    bool
                   </em>
                  </a>
                  ) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.
                 </p>
                </li>
               </ul>
              </dd>
              <dt class="field-even">
               Yields
              </dt>
              <dd class="field-even">
               <p>
                <em>
                 (string, torch.Tensor)
                </em>
                – Tuple containing the name and buffer
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'running_var'</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.named_children">
             <code class="sig-name descname">
              <span class="pre">
               named_children
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.named_children">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.named_children" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Yields
              </dt>
              <dd class="field-odd">
               <p>
                <em>
                 (string, Module)
                </em>
                – Tuple containing a name and child module
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'conv4'</span><span class="p">,</span> <span class="s1">'conv5'</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.named_modules">
             <code class="sig-name descname">
              <span class="pre">
               named_modules
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                memo
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                None
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                prefix
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                ''
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                remove_duplicate
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.named_modules">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.named_modules" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   memo
                  </strong>
                  – a memo to store the set of modules already added to the result
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   prefix
                  </strong>
                  – a prefix that will be added to the name of the module
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   remove_duplicate
                  </strong>
                  – whether to remove the duplicated module instances in the result
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   not
                  </strong>
                  (
                  <em>
                   or
                  </em>
                  ) –
                 </p>
                </li>
               </ul>
              </dd>
              <dt class="field-even">
               Yields
              </dt>
              <dd class="field-even">
               <p>
                <em>
                 (string, Module)
                </em>
                – Tuple of name and module
               </p>
              </dd>
             </dl>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               Duplicate modules are returned only once. In the following
example,
               <code class="docutils literal notranslate">
                <span class="pre">
                 l
                </span>
               </code>
               will be returned only once.
              </p>
             </div>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="go">        print(idx, '-&gt;', m)</span>

<span class="go">0 -&gt; ('', Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; ('0', Linear(in_features=2, out_features=2, bias=True))</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.named_parameters">
             <code class="sig-name descname">
              <span class="pre">
               named_parameters
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                prefix
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                ''
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                recurse
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.named_parameters">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.named_parameters" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   prefix
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)">
                   <em>
                    str
                   </em>
                  </a>
                  ) – prefix to prepend to all parameter names.
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   recurse
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                   <em>
                    bool
                   </em>
                  </a>
                  ) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.
                 </p>
                </li>
               </ul>
              </dd>
              <dt class="field-even">
               Yields
              </dt>
              <dd class="field-even">
               <p>
                <em>
                 (string, Parameter)
                </em>
                – Tuple containing the name and parameter
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'bias'</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.parameters">
             <code class="sig-name descname">
              <span class="pre">
               parameters
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                recurse
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.parameters">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.parameters" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns an iterator over module parameters.
             </p>
             <p>
              This is typically passed to an optimizer.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 recurse
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                ) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.
               </p>
              </dd>
              <dt class="field-even">
               Yields
              </dt>
              <dd class="field-even">
               <p>
                <em>
                 Parameter
                </em>
                – module parameter
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L,)</span>
<span class="go">&lt;class 'torch.Tensor'&gt; (20L, 1L, 5L, 5L)</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.register_backward_hook">
             <code class="sig-name descname">
              <span class="pre">
               register_backward_hook
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                hook
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.register_backward_hook">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.register_backward_hook" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Registers a backward hook on the module.
             </p>
             <p>
              This function is deprecated in favor of
              <a class="reference internal" href="#torch.nn.Module.register_full_backward_hook" title="torch.nn.Module.register_full_backward_hook">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 register_full_backward_hook()
                </span>
               </code>
              </a>
              and
the behavior of this function will change in future versions.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                a handle that can be used to remove the added hook by calling
                <code class="docutils literal notranslate">
                 <span class="pre">
                  handle.remove()
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.utils.hooks.RemovableHandle
                 </span>
                </code>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.register_buffer">
             <code class="sig-name descname">
              <span class="pre">
               register_buffer
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                name
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                tensor
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                persistent
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.register_buffer">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.register_buffer" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Adds a buffer to the module.
             </p>
             <p>
              This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s
              <code class="docutils literal notranslate">
               <span class="pre">
                running_mean
               </span>
              </code>
              is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                persistent
               </span>
              </code>
              to
              <code class="docutils literal notranslate">
               <span class="pre">
                False
               </span>
              </code>
              . The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
              <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 state_dict
                </span>
               </code>
              </a>
              .
             </p>
             <p>
              Buffers can be accessed as attributes using given names.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   name
                  </strong>
                  (
                  <em>
                   string
                  </em>
                  ) – name of the buffer. The buffer can be accessed
from this module using the given name
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   tensor
                  </strong>
                  (
                  <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
                   <em>
                    Tensor
                   </em>
                  </a>
                  <em>
                   or
                  </em>
                  <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.10)">
                   <em>
                    None
                   </em>
                  </a>
                  ) – buffer to be registered. If
                  <code class="docutils literal notranslate">
                   <span class="pre">
                    None
                   </span>
                  </code>
                  , then operations
that run on buffers, such as
                  <a class="reference internal" href="#torch.nn.Module.cuda" title="torch.nn.Module.cuda">
                   <code class="xref py py-attr docutils literal notranslate">
                    <span class="pre">
                     cuda
                    </span>
                   </code>
                  </a>
                  , are ignored. If
                  <code class="docutils literal notranslate">
                   <span class="pre">
                    None
                   </span>
                  </code>
                  ,
the buffer is
                  <strong>
                   not
                  </strong>
                  included in the module’s
                  <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
                   <code class="xref py py-attr docutils literal notranslate">
                    <span class="pre">
                     state_dict
                    </span>
                   </code>
                  </a>
                  .
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   persistent
                  </strong>
                  (
                  <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                   <em>
                    bool
                   </em>
                  </a>
                  ) – whether the buffer is part of this module’s
                  <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
                   <code class="xref py py-attr docutils literal notranslate">
                    <span class="pre">
                     state_dict
                    </span>
                   </code>
                  </a>
                  .
                 </p>
                </li>
               </ul>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'running_mean'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.register_forward_hook">
             <code class="sig-name descname">
              <span class="pre">
               register_forward_hook
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                hook
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.register_forward_hook">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.register_forward_hook" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Registers a forward hook on the module.
             </p>
             <p>
              The hook will be called every time after
              <a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward">
               <code class="xref py py-func docutils literal notranslate">
                <span class="pre">
                 forward()
                </span>
               </code>
              </a>
              has computed an output.
It should have the following signature:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre>
              </div>
             </div>
             <p>
              The input contains only the positional arguments given to the module.
Keyword arguments won’t be passed to the hooks and only to the
              <code class="docutils literal notranslate">
               <span class="pre">
                forward
               </span>
              </code>
              .
The hook can modify the output. It can modify the input inplace but
it will not have effect on forward since this is called after
              <a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward">
               <code class="xref py py-func docutils literal notranslate">
                <span class="pre">
                 forward()
                </span>
               </code>
              </a>
              is called.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                a handle that can be used to remove the added hook by calling
                <code class="docutils literal notranslate">
                 <span class="pre">
                  handle.remove()
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.utils.hooks.RemovableHandle
                 </span>
                </code>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.register_forward_pre_hook">
             <code class="sig-name descname">
              <span class="pre">
               register_forward_pre_hook
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                hook
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.register_forward_pre_hook">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.register_forward_pre_hook" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Registers a forward pre-hook on the module.
             </p>
             <p>
              The hook will be called every time before
              <a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward">
               <code class="xref py py-func docutils literal notranslate">
                <span class="pre">
                 forward()
                </span>
               </code>
              </a>
              is invoked.
It should have the following signature:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre>
              </div>
             </div>
             <p>
              The input contains only the positional arguments given to the module.
Keyword arguments won’t be passed to the hooks and only to the
              <code class="docutils literal notranslate">
               <span class="pre">
                forward
               </span>
              </code>
              .
The hook can modify the input. User can either return a tuple or a
single modified value in the hook. We will wrap the value into a tuple
if a single value is returned(unless that value is already a tuple).
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                a handle that can be used to remove the added hook by calling
                <code class="docutils literal notranslate">
                 <span class="pre">
                  handle.remove()
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.utils.hooks.RemovableHandle
                 </span>
                </code>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.register_full_backward_hook">
             <code class="sig-name descname">
              <span class="pre">
               register_full_backward_hook
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                hook
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.register_full_backward_hook">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.register_full_backward_hook" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Registers a backward hook on the module.
             </p>
             <p>
              The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre>
              </div>
             </div>
             <p>
              The
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                grad_input
               </span>
              </code>
              and
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                grad_output
               </span>
              </code>
              are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                grad_input
               </span>
              </code>
              in
subsequent computations.
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                grad_input
               </span>
              </code>
              will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                grad_input
               </span>
              </code>
              and
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                grad_output
               </span>
              </code>
              will be
              <code class="docutils literal notranslate">
               <span class="pre">
                None
               </span>
              </code>
              for all non-Tensor
arguments.
             </p>
             <p>
              For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.
             </p>
             <div class="admonition warning">
              <p class="admonition-title">
               Warning
              </p>
              <p>
               Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                a handle that can be used to remove the added hook by calling
                <code class="docutils literal notranslate">
                 <span class="pre">
                  handle.remove()
                 </span>
                </code>
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.utils.hooks.RemovableHandle
                 </span>
                </code>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.register_parameter">
             <code class="sig-name descname">
              <span class="pre">
               register_parameter
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                name
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                param
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.register_parameter">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.register_parameter" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Adds a parameter to the module.
             </p>
             <p>
              The parameter can be accessed as an attribute using given name.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   name
                  </strong>
                  (
                  <em>
                   string
                  </em>
                  ) – name of the parameter. The parameter can be accessed
from this module using the given name
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   param
                  </strong>
                  (
                  <a class="reference internal" href="torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter">
                   <em>
                    Parameter
                   </em>
                  </a>
                  <em>
                   or
                  </em>
                  <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.10)">
                   <em>
                    None
                   </em>
                  </a>
                  ) – parameter to be added to the module. If
                  <code class="docutils literal notranslate">
                   <span class="pre">
                    None
                   </span>
                  </code>
                  , then operations that run on parameters, such as
                  <a class="reference internal" href="#torch.nn.Module.cuda" title="torch.nn.Module.cuda">
                   <code class="xref py py-attr docutils literal notranslate">
                    <span class="pre">
                     cuda
                    </span>
                   </code>
                  </a>
                  ,
are ignored. If
                  <code class="docutils literal notranslate">
                   <span class="pre">
                    None
                   </span>
                  </code>
                  , the parameter is
                  <strong>
                   not
                  </strong>
                  included in the
module’s
                  <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict">
                   <code class="xref py py-attr docutils literal notranslate">
                    <span class="pre">
                     state_dict
                    </span>
                   </code>
                  </a>
                  .
                 </p>
                </li>
               </ul>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.requires_grad_">
             <code class="sig-name descname">
              <span class="pre">
               requires_grad_
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                requires_grad
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.requires_grad_">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.requires_grad_" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Change if autograd should record operations on parameters in this
module.
             </p>
             <p>
              This method sets the parameters’
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                requires_grad
               </span>
              </code>
              attributes
in-place.
             </p>
             <p>
              This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).
             </p>
             <p>
              See
              <a class="reference internal" href="../notes/autograd.html#locally-disable-grad-doc">
               <span class="std std-ref">
                Locally disabling gradient computation
               </span>
              </a>
              for a comparison between
              <cite>
               .requires_grad_()
              </cite>
              and several similar mechanisms that may be confused with it.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 requires_grad
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                ) – whether autograd should record operations on
parameters in this module. Default:
                <code class="docutils literal notranslate">
                 <span class="pre">
                  True
                 </span>
                </code>
                .
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.set_extra_state">
             <code class="sig-name descname">
              <span class="pre">
               set_extra_state
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                state
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.set_extra_state">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.set_extra_state" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              This function is called from
              <a class="reference internal" href="#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict">
               <code class="xref py py-func docutils literal notranslate">
                <span class="pre">
                 load_state_dict()
                </span>
               </code>
              </a>
              to handle any extra state
found within the
              <cite>
               state_dict
              </cite>
              . Implement this function and a corresponding
              <a class="reference internal" href="#torch.nn.Module.get_extra_state" title="torch.nn.Module.get_extra_state">
               <code class="xref py py-func docutils literal notranslate">
                <span class="pre">
                 get_extra_state()
                </span>
               </code>
              </a>
              for your module if you need to store extra state within its
              <cite>
               state_dict
              </cite>
              .
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 state
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.10)">
                 <em>
                  dict
                 </em>
                </a>
                ) – Extra state from the
                <cite>
                 state_dict
                </cite>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.share_memory">
             <code class="sig-name descname">
              <span class="pre">
               share_memory
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.share_memory">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.share_memory" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              See
              <a class="reference internal" href="torch.Tensor.share_memory_.html#torch.Tensor.share_memory_" title="torch.Tensor.share_memory_">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 torch.Tensor.share_memory_()
                </span>
               </code>
              </a>
             </p>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.state_dict">
             <code class="sig-name descname">
              <span class="pre">
               state_dict
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                destination
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                None
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                prefix
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                ''
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                keep_vars
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                False
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.state_dict">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.state_dict" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns a dictionary containing a whole state of the module.
             </p>
             <p>
              Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to
              <code class="docutils literal notranslate">
               <span class="pre">
                None
               </span>
              </code>
              are not included.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                a dictionary containing a whole state of the module
               </p>
              </dd>
              <dt class="field-even">
               Return type
              </dt>
              <dd class="field-even">
               <p>
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.10)">
                 dict
                </a>
               </p>
              </dd>
             </dl>
             <p>
              Example:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">['bias', 'weight']</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.to">
             <code class="sig-name descname">
              <span class="pre">
               to
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="o">
               <span class="pre">
                *
               </span>
              </span>
              <span class="n">
               <span class="pre">
                args
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="o">
               <span class="pre">
                **
               </span>
              </span>
              <span class="n">
               <span class="pre">
                kwargs
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.to">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.to" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Moves and/or casts the parameters and buffers.
             </p>
             <p>
              This can be called as
             </p>
             <dl class="py function">
              <dt>
               <code class="sig-name descname">
                <span class="pre">
                 to
                </span>
               </code>
               <span class="sig-paren">
                (
               </span>
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  device
                 </span>
                </span>
                <span class="o">
                 <span class="pre">
                  =
                 </span>
                </span>
                <span class="default_value">
                 <span class="pre">
                  None
                 </span>
                </span>
               </em>
               ,
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  dtype
                 </span>
                </span>
                <span class="o">
                 <span class="pre">
                  =
                 </span>
                </span>
                <span class="default_value">
                 <span class="pre">
                  None
                 </span>
                </span>
               </em>
               ,
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  non_blocking
                 </span>
                </span>
                <span class="o">
                 <span class="pre">
                  =
                 </span>
                </span>
                <span class="default_value">
                 <span class="pre">
                  False
                 </span>
                </span>
               </em>
               <span class="sig-paren">
                )
               </span>
               <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.to">
                <span class="viewcode-link">
                 <span class="pre">
                  [source]
                 </span>
                </span>
               </a>
              </dt>
              <dd>
              </dd>
             </dl>
             <dl class="py function">
              <dt>
               <code class="sig-name descname">
                <span class="pre">
                 to
                </span>
               </code>
               <span class="sig-paren">
                (
               </span>
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  dtype
                 </span>
                </span>
               </em>
               ,
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  non_blocking
                 </span>
                </span>
                <span class="o">
                 <span class="pre">
                  =
                 </span>
                </span>
                <span class="default_value">
                 <span class="pre">
                  False
                 </span>
                </span>
               </em>
               <span class="sig-paren">
                )
               </span>
               <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.to">
                <span class="viewcode-link">
                 <span class="pre">
                  [source]
                 </span>
                </span>
               </a>
              </dt>
              <dd>
              </dd>
             </dl>
             <dl class="py function">
              <dt>
               <code class="sig-name descname">
                <span class="pre">
                 to
                </span>
               </code>
               <span class="sig-paren">
                (
               </span>
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  tensor
                 </span>
                </span>
               </em>
               ,
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  non_blocking
                 </span>
                </span>
                <span class="o">
                 <span class="pre">
                  =
                 </span>
                </span>
                <span class="default_value">
                 <span class="pre">
                  False
                 </span>
                </span>
               </em>
               <span class="sig-paren">
                )
               </span>
               <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.to">
                <span class="viewcode-link">
                 <span class="pre">
                  [source]
                 </span>
                </span>
               </a>
              </dt>
              <dd>
              </dd>
             </dl>
             <dl class="py function">
              <dt>
               <code class="sig-name descname">
                <span class="pre">
                 to
                </span>
               </code>
               <span class="sig-paren">
                (
               </span>
               <em class="sig-param">
                <span class="n">
                 <span class="pre">
                  memory_format
                 </span>
                </span>
                <span class="o">
                 <span class="pre">
                  =
                 </span>
                </span>
                <span class="default_value">
                 <span class="pre">
                  torch.channels_last
                 </span>
                </span>
               </em>
               <span class="sig-paren">
                )
               </span>
               <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.to">
                <span class="viewcode-link">
                 <span class="pre">
                  [source]
                 </span>
                </span>
               </a>
              </dt>
              <dd>
              </dd>
             </dl>
             <p>
              Its signature is similar to
              <a class="reference internal" href="torch.Tensor.to.html#torch.Tensor.to" title="torch.Tensor.to">
               <code class="xref py py-meth docutils literal notranslate">
                <span class="pre">
                 torch.Tensor.to()
                </span>
               </code>
              </a>
              , but only accepts
floating point or complex
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                dtype
               </span>
              </code>
              s. In addition, this method will
only cast the floating point or complex parameters and buffers to
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                dtype
               </span>
              </code>
              (if given). The integral parameters and buffers will be moved
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                device
               </span>
              </code>
              , if that is given, but with dtypes unchanged. When
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                non_blocking
               </span>
              </code>
              is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.
             </p>
             <p>
              See below for examples.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   device
                  </strong>
                  (
                  <code class="xref py py-class docutils literal notranslate">
                   <span class="pre">
                    torch.device
                   </span>
                  </code>
                  ) – the desired device of the parameters
and buffers in this module
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   dtype
                  </strong>
                  (
                  <code class="xref py py-class docutils literal notranslate">
                   <span class="pre">
                    torch.dtype
                   </span>
                  </code>
                  ) – the desired floating point or complex dtype of
the parameters and buffers in this module
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   tensor
                  </strong>
                  (
                  <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
                   <em>
                    torch.Tensor
                   </em>
                  </a>
                  ) – Tensor whose dtype and device are the desired
dtype and device for all parameters and buffers in this module
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   memory_format
                  </strong>
                  (
                  <code class="xref py py-class docutils literal notranslate">
                   <span class="pre">
                    torch.memory_format
                   </span>
                  </code>
                  ) – the desired memory
format for 4D parameters and buffers in this module (keyword
only argument)
                 </p>
                </li>
               </ul>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
             <p>
              Examples:
             </p>
             <div class="highlight-default notranslate">
              <div class="highlight">
               <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:1"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.3741+0.j,  0.2382+0.j],</span>
<span class="go">        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">))</span>
<span class="go">tensor([[0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)</span>
</pre>
              </div>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.to_empty">
             <code class="sig-name descname">
              <span class="pre">
               to_empty
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="o">
               <span class="pre">
                *
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                device
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.to_empty">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.to_empty" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Moves the parameters and buffers to the specified device without copying storage.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 device
                </strong>
                (
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.device
                 </span>
                </code>
                ) – The desired device of the parameters
and buffers in this module.
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.train">
             <code class="sig-name descname">
              <span class="pre">
               train
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                mode
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                True
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.train">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.train" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Sets the module in training mode.
             </p>
             <p>
              This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g.
              <a class="reference internal" href="torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout">
               <code class="xref py py-class docutils literal notranslate">
                <span class="pre">
                 Dropout
                </span>
               </code>
              </a>
              ,
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                BatchNorm
               </span>
              </code>
              ,
etc.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 mode
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                ) – whether to set training mode (
                <code class="docutils literal notranslate">
                 <span class="pre">
                  True
                 </span>
                </code>
                ) or evaluation
mode (
                <code class="docutils literal notranslate">
                 <span class="pre">
                  False
                 </span>
                </code>
                ). Default:
                <code class="docutils literal notranslate">
                 <span class="pre">
                  True
                 </span>
                </code>
                .
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.type">
             <code class="sig-name descname">
              <span class="pre">
               type
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                dst_type
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.type">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.type" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Casts all parameters and buffers to
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                dst_type
               </span>
              </code>
              .
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 dst_type
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.10)">
                 <em>
                  type
                 </em>
                </a>
                <em>
                 or
                </em>
                <em>
                 string
                </em>
                ) – the desired type
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.xpu">
             <code class="sig-name descname">
              <span class="pre">
               xpu
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                device
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                None
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.xpu">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.xpu" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Moves all model parameters and buffers to the XPU.
             </p>
             <p>
              This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This method modifies the module in-place.
              </p>
             </div>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 device
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                 <em>
                  int
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – if specified, all parameters will be
copied to that device
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                self
               </p>
              </dd>
              <dt class="field-odd">
               Return type
              </dt>
              <dd class="field-odd">
               <p>
                <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">
                 Module
                </a>
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.nn.Module.zero_grad">
             <code class="sig-name descname">
              <span class="pre">
               zero_grad
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                set_to_none
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                False
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/nn/modules/module.html#Module.zero_grad">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.nn.Module.zero_grad" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Sets gradients of all model parameters to zero. See similar function
under
              <a class="reference internal" href="../optim.html#torch.optim.Optimizer" title="torch.optim.Optimizer">
               <code class="xref py py-class docutils literal notranslate">
                <span class="pre">
                 torch.optim.Optimizer
                </span>
               </code>
              </a>
              for more context.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 set_to_none
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                ) – instead of setting to zero, set the grads to None.
See
                <a class="reference internal" href="torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad" title="torch.optim.Optimizer.zero_grad">
                 <code class="xref py py-meth docutils literal notranslate">
                  <span class="pre">
                   torch.optim.Optimizer.zero_grad()
                  </span>
                 </code>
                </a>
                for details.
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>