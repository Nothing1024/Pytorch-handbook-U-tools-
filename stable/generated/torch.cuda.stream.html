<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   Stream — PyTorch 1.10 documentation
  </title>
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="stream">
         <h1>
          Stream
          <a class="headerlink" href="#stream" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py class">
          <dt id="torch.cuda.Stream">
           <em class="property">
            <span class="pre">
             class
            </span>
           </em>
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.cuda.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             Stream
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              device
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              priority
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              0
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="o">
             <span class="pre">
              **
             </span>
            </span>
            <span class="n">
             <span class="pre">
              kwargs
             </span>
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="reference internal" href="../_modules/torch/cuda/streams.html#Stream">
            <span class="viewcode-link">
             <span class="pre">
              [source]
             </span>
            </span>
           </a>
           <a class="headerlink" href="#torch.cuda.Stream" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Wrapper around a CUDA stream.
           </p>
           <p>
            A CUDA stream is a linear sequence of execution that belongs to a specific
device, independent from other streams.  See
            <a class="reference internal" href="../notes/cuda.html#cuda-semantics">
             <span class="std std-ref">
              CUDA semantics
             </span>
            </a>
            for
details.
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 device
                </strong>
                (
                <a class="reference internal" href="../tensor_attributes.html#torch.torch.device" title="torch.torch.device">
                 <em>
                  torch.device
                 </em>
                </a>
                <em>
                 or
                </em>
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                 <em>
                  int
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – a device on which to allocate
the stream. If
                <a class="reference internal" href="torch.cuda.device.html#torch.cuda.device" title="torch.cuda.device">
                 <code class="xref py py-attr docutils literal notranslate">
                  <span class="pre">
                   device
                  </span>
                 </code>
                </a>
                is
                <code class="docutils literal notranslate">
                 <span class="pre">
                  None
                 </span>
                </code>
                (default) or a negative
integer, this will use the current device.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 priority
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                 <em>
                  int
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – priority of the stream. Can be either
-1 (high priority) or 0 (low priority). By default, streams have
priority 0.
               </p>
              </li>
             </ul>
            </dd>
           </dl>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             Although CUDA versions &gt;= 11 support more than two levels of
priorities, in PyTorch, we only support two levels of priorities.
            </p>
           </div>
           <dl class="py method">
            <dt id="torch.cuda.Stream.query">
             <code class="sig-name descname">
              <span class="pre">
               query
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/cuda/streams.html#Stream.query">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.cuda.Stream.query" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Checks if all the work submitted has been completed.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Returns
              </dt>
              <dd class="field-odd">
               <p>
                A boolean indicating if all kernels in this stream are completed.
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.cuda.Stream.record_event">
             <code class="sig-name descname">
              <span class="pre">
               record_event
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                event
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                None
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/cuda/streams.html#Stream.record_event">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.cuda.Stream.record_event" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Records an event.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 event
                </strong>
                (
                <a class="reference internal" href="torch.cuda.Event.html#torch.cuda.Event" title="torch.cuda.Event">
                 <em>
                  torch.cuda.Event
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – event to record. If not given, a new one
will be allocated.
               </p>
              </dd>
              <dt class="field-even">
               Returns
              </dt>
              <dd class="field-even">
               <p>
                Recorded event.
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.cuda.Stream.synchronize">
             <code class="sig-name descname">
              <span class="pre">
               synchronize
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/cuda/streams.html#Stream.synchronize">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.cuda.Stream.synchronize" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Wait for all the kernels in this stream to complete.
             </p>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This is a wrapper around
               <code class="docutils literal notranslate">
                <span class="pre">
                 cudaStreamSynchronize()
                </span>
               </code>
               : see
               <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html">
                CUDA Stream documentation
               </a>
               for more info.
              </p>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.cuda.Stream.wait_event">
             <code class="sig-name descname">
              <span class="pre">
               wait_event
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                event
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/cuda/streams.html#Stream.wait_event">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.cuda.Stream.wait_event" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Makes all future work submitted to the stream wait for an event.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 event
                </strong>
                (
                <a class="reference internal" href="torch.cuda.Event.html#torch.cuda.Event" title="torch.cuda.Event">
                 <em>
                  torch.cuda.Event
                 </em>
                </a>
                ) – an event to wait for.
               </p>
              </dd>
             </dl>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This is a wrapper around
               <code class="docutils literal notranslate">
                <span class="pre">
                 cudaStreamWaitEvent()
                </span>
               </code>
               : see
               <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html">
                CUDA Stream documentation
               </a>
               for more info.
              </p>
              <p>
               This function returns without waiting for
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 event
                </span>
               </code>
               : only future
operations are affected.
              </p>
             </div>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.cuda.Stream.wait_stream">
             <code class="sig-name descname">
              <span class="pre">
               wait_stream
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                stream
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/cuda/streams.html#Stream.wait_stream">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.cuda.Stream.wait_stream" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Synchronizes with another stream.
             </p>
             <p>
              All future work submitted to this stream will wait until all kernels
submitted to a given stream at the time of call complete.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 stream
                </strong>
                (
                <a class="reference internal" href="#torch.cuda.Stream" title="torch.cuda.Stream">
                 <em>
                  Stream
                 </em>
                </a>
                ) – a stream to synchronize.
               </p>
              </dd>
             </dl>
             <div class="admonition note">
              <p class="admonition-title">
               Note
              </p>
              <p>
               This function returns without waiting for currently enqueued
kernels in
               <a class="reference internal" href="torch.cuda.stream.html#torch.cuda.stream" title="torch.cuda.stream">
                <code class="xref py py-attr docutils literal notranslate">
                 <span class="pre">
                  stream
                 </span>
                </code>
               </a>
               : only future operations are affected.
              </p>
             </div>
            </dd>
           </dl>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>