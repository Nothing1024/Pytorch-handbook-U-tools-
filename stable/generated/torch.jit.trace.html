<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.jit.trace — PyTorch 1.11.0 documentation
  </title>
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- End Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="torch-jit-trace">
         <h1>
          torch.jit.trace
          <a class="headerlink" href="#torch-jit-trace" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py function">
          <dt id="torch.jit.trace">
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.jit.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             trace
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="pre">
             func
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             example_inputs
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             optimize=None
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             check_trace=True
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             check_inputs=None
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             check_tolerance=1e-05
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             strict=True
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             _force_outplace=False
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             _module_class=None
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             _compilation_unit=&lt;torch.jit.CompilationUnit
            </span>
            <span class="pre">
             object&gt;
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="reference internal" href="../_modules/torch/jit/_trace.html#trace">
            <span class="viewcode-link">
             <span class="pre">
              [source]
             </span>
            </span>
           </a>
           <a class="headerlink" href="#torch.jit.trace" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Trace a function and return an executable  or
            <a class="reference internal" href="torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.ScriptFunction">
             <code class="xref py py-class docutils literal notranslate">
              <span class="pre">
               ScriptFunction
              </span>
             </code>
            </a>
            that will be optimized using just-in-time compilation. Tracing is ideal for
code that operates only on
            <code class="docutils literal notranslate">
             <span class="pre">
              Tensor
             </span>
            </code>
            s and lists, dictionaries, and
tuples of
            <code class="docutils literal notranslate">
             <span class="pre">
              Tensor
             </span>
            </code>
            s.
           </p>
           <p>
            Using
            <cite>
             torch.jit.trace
            </cite>
            and
            <cite>
             torch.jit.trace_module
            </cite>
            , you can turn an
existing module or Python function into a TorchScript
            <a class="reference internal" href="torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.ScriptFunction">
             <code class="xref py py-class docutils literal notranslate">
              <span class="pre">
               ScriptFunction
              </span>
             </code>
            </a>
            or
            <a class="reference internal" href="torch.jit.ScriptModule.html#torch.jit.ScriptModule" title="torch.jit.ScriptModule">
             <code class="xref py py-class docutils literal notranslate">
              <span class="pre">
               ScriptModule
              </span>
             </code>
            </a>
            . You must provide example
inputs, and we run the function, recording the operations performed on all
the tensors.
           </p>
           <ul class="simple">
            <li>
             <p>
              The resulting recording of a standalone function produces
              <cite>
               ScriptFunction
              </cite>
              .
             </p>
            </li>
            <li>
             <p>
              The resulting recording of
              <cite>
               nn.Module.forward
              </cite>
              or
              <cite>
               nn.Module
              </cite>
              produces
              <cite>
               ScriptModule
              </cite>
              .
             </p>
            </li>
           </ul>
           <p>
            This module also contains any parameters that the original
module had as well.
           </p>
           <div class="admonition warning">
            <p class="admonition-title">
             Warning
            </p>
            <p>
             Tracing only correctly records functions and modules which are not data
dependent (e.g., do not have conditionals on data in tensors) and do not have
any untracked external dependencies (e.g., perform input/output or
access global variables). Tracing only records operations done when the given
function is run on the given tensors. Therefore, the returned
             <cite>
              ScriptModule
             </cite>
             will always run the same traced graph on any input. This
has some important implications when your module is expected to run
different sets of operations, depending on the input and/or the module
state. For example,
            </p>
            <ul class="simple">
             <li>
              <p>
               Tracing will not record any control-flow like if-statements or loops.
When this control-flow is constant across your module, this is fine
and it often inlines the control-flow decisions. But sometimes the
control-flow is actually part of the model itself. For instance, a
recurrent network is a loop over the (possibly dynamic) length of an
input sequence.
              </p>
             </li>
             <li>
              <p>
               In the returned
               <a class="reference internal" href="torch.jit.ScriptModule.html#torch.jit.ScriptModule" title="torch.jit.ScriptModule">
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  ScriptModule
                 </span>
                </code>
               </a>
               , operations that have different
behaviors in
               <code class="docutils literal notranslate">
                <span class="pre">
                 training
                </span>
               </code>
               and
               <code class="docutils literal notranslate">
                <span class="pre">
                 eval
                </span>
               </code>
               modes will always behave as if
it is in the mode it was in during tracing, no matter which mode the
               <cite>
                ScriptModule
               </cite>
               is in.
              </p>
             </li>
            </ul>
            <p>
             In cases like these, tracing would not be appropriate and
             <a class="reference internal" href="torch.jit.script.html#torch.jit.script" title="torch.jit.script">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                scripting
               </span>
              </code>
             </a>
             is a better choice. If you trace
such models, you may silently get incorrect results on subsequent
invocations of the model. The tracer will try to emit warnings when
doing something that may cause an incorrect trace to be produced.
            </p>
           </div>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 func
                </strong>
                (
                <em>
                 callable
                </em>
                <em>
                 or
                </em>
                <a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module">
                 <em>
                  torch.nn.Module
                 </em>
                </a>
                ) – A Python function or
                <cite>
                 torch.nn.Module
                </cite>
                that will be run with
                <cite>
                 example_inputs
                </cite>
                .
                <cite>
                 func
                </cite>
                arguments and return
values  must be tensors or (possibly nested) tuples that contain
tensors. When a module is passed
                <cite>
                 torch.jit.trace
                </cite>
                , only the
                <code class="docutils literal notranslate">
                 <span class="pre">
                  forward
                 </span>
                </code>
                method is run and traced (see
                <a class="reference internal" href="torch.jit.trace_module.html#torch.jit.trace_module" title="torch.jit.trace_module">
                 <code class="xref py py-func docutils literal notranslate">
                  <span class="pre">
                   torch.jit.trace
                  </span>
                 </code>
                </a>
                for details).
               </p>
              </li>
              <li>
               <p>
                <strong>
                 example_inputs
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.10)">
                 <em>
                  tuple
                 </em>
                </a>
                <em>
                 or
                </em>
                <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
                 <em>
                  torch.Tensor
                 </em>
                </a>
                ) – A tuple of example inputs that
will be passed to the function while tracing. The resulting trace
can be run with inputs of different types and shapes assuming the
traced operations support those types and shapes.
                <cite>
                 example_inputs
                </cite>
                may also be a single Tensor in which case it is automatically
wrapped in a tuple.
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 check_trace
                </strong>
                (
                <code class="docutils literal notranslate">
                 <span class="pre">
                  bool
                 </span>
                </code>
                , optional) – Check if the same inputs run through
traced code produce the same outputs. Default:
                <code class="docutils literal notranslate">
                 <span class="pre">
                  True
                 </span>
                </code>
                . You might want
to disable this if, for example, your network contains non-
deterministic ops or if you are sure that the network is correct despite
a checker failure.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 check_inputs
                </strong>
                (
                <em>
                 list of tuples
                </em>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – A list of tuples of input
arguments that should be used to check the trace against what is
expected. Each tuple is equivalent to a set of input arguments that
would be specified in
                <code class="docutils literal notranslate">
                 <span class="pre">
                  example_inputs
                 </span>
                </code>
                . For best results, pass in
a set of checking inputs representative of the space of shapes and
types of inputs you expect the network to see.  If not specified,
the original
                <code class="docutils literal notranslate">
                 <span class="pre">
                  example_inputs
                 </span>
                </code>
                are used for checking
               </p>
              </li>
              <li>
               <p>
                <strong>
                 check_tolerance
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)">
                 <em>
                  float
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – Floating-point comparison tolerance
to use in the checker procedure.  This can be used to relax the
checker strictness in the event that results diverge numerically
for a known reason, such as operator fusion.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 strict
                </strong>
                (
                <code class="docutils literal notranslate">
                 <span class="pre">
                  bool
                 </span>
                </code>
                , optional) – run the tracer in a strict mode or not
(default:
                <code class="docutils literal notranslate">
                 <span class="pre">
                  True
                 </span>
                </code>
                ). Only turn this off when you want the tracer to
record your mutable container types (currently
                <code class="docutils literal notranslate">
                 <span class="pre">
                  list
                 </span>
                </code>
                /
                <code class="docutils literal notranslate">
                 <span class="pre">
                  dict
                 </span>
                </code>
                )
and you are sure that the container you are using in your
problem is a
                <code class="docutils literal notranslate">
                 <span class="pre">
                  constant
                 </span>
                </code>
                structure and does not get used as
control flow (if, for) conditions.
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-odd">
             Returns
            </dt>
            <dd class="field-odd">
             <p>
              If
              <cite>
               func
              </cite>
              is
              <cite>
               nn.Module
              </cite>
              or
              <code class="docutils literal notranslate">
               <span class="pre">
                forward
               </span>
              </code>
              of
              <cite>
               nn.Module
              </cite>
              ,
              <cite>
               trace
              </cite>
              returns
a
              <a class="reference internal" href="torch.jit.ScriptModule.html#torch.jit.ScriptModule" title="torch.jit.ScriptModule">
               <code class="xref py py-class docutils literal notranslate">
                <span class="pre">
                 ScriptModule
                </span>
               </code>
              </a>
              object with a single
              <code class="docutils literal notranslate">
               <span class="pre">
                forward
               </span>
              </code>
              method
containing the traced code.  The returned
              <cite>
               ScriptModule
              </cite>
              will
have the same set of sub-modules and parameters as the original
              <code class="docutils literal notranslate">
               <span class="pre">
                nn.Module
               </span>
              </code>
              .  If
              <code class="docutils literal notranslate">
               <span class="pre">
                func
               </span>
              </code>
              is a standalone function,
              <code class="docutils literal notranslate">
               <span class="pre">
                trace
               </span>
              </code>
              returns
              <cite>
               ScriptFunction
              </cite>
              .
             </p>
            </dd>
           </dl>
           <p>
            Example (tracing a function):
           </p>
           <div class="highlight-python3 notranslate">
            <div class="highlight">
             <pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

<span class="c1"># Run `foo` with the provided inputs and record the tensor operations</span>
<span class="n">traced_foo</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">foo</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)))</span>

<span class="c1"># `traced_foo` can now be run with the TorchScript interpreter or saved</span>
<span class="c1"># and loaded in a Python-free environment</span>
</pre>
            </div>
           </div>
           <p>
            Example (tracing an existing module):
           </p>
           <div class="highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">example_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">example_forward_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Trace a specific method and construct `ScriptModule` with</span>
<span class="c1"># a single `forward` method</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">forward</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">)</span>

<span class="c1"># Trace a module (implicitly traces `forward`) and construct a</span>
<span class="c1"># `ScriptModule` with a single `forward` method</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">)</span>
</pre>
            </div>
           </div>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>