<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.svd — PyTorch 1.12 documentation
  </title>
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- End Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="torch-svd">
         <h1>
          torch.svd
          <a class="headerlink" href="#torch-svd" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py function">
          <dt id="torch.svd">
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             svd
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              input
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              some
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              True
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              compute_uv
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              True
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="o">
             <span class="pre">
              *
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              out
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="headerlink" href="#torch.svd" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Computes the singular value decomposition of either a matrix or batch of
matrices
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            . The singular value decomposition is represented as a
namedtuple
            <cite>
             (U, S, V)
            </cite>
            , such that
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            <span class="math">
             <span class="katex">
              <span class="katex-mathml">
               <math xmlns="http://www.w3.org/1998/Math/MathML">
                <semantics>
                 <mrow>
                  <mo>
                   =
                  </mo>
                  <mi>
                   U
                  </mi>
                  <mtext>
                   diag
                  </mtext>
                  <mo stretchy="false">
                   (
                  </mo>
                  <mi>
                   S
                  </mi>
                  <mo stretchy="false">
                   )
                  </mo>
                  <msup>
                   <mi>
                    V
                   </mi>
                   <mtext>
                    H
                   </mtext>
                  </msup>
                 </mrow>
                 <annotation encoding="application/x-tex">
                  = U \text{diag}(S) V^{\text{H}}
                 </annotation>
                </semantics>
               </math>
              </span>
              <span aria-hidden="true" class="katex-html">
               <span class="base">
                <span class="strut" style="height:0.3669em;">
                </span>
                <span class="mrel">
                 =
                </span>
                <span class="mspace" style="margin-right:0.2778em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height:1.0913em;vertical-align:-0.25em;">
                </span>
                <span class="mord mathnormal" style="margin-right:0.10903em;">
                 U
                </span>
                <span class="mord text">
                 <span class="mord">
                  diag
                 </span>
                </span>
                <span class="mopen">
                 (
                </span>
                <span class="mord mathnormal" style="margin-right:0.05764em;">
                 S
                </span>
                <span class="mclose">
                 )
                </span>
                <span class="mord">
                 <span class="mord mathnormal" style="margin-right:0.22222em;">
                  V
                 </span>
                 <span class="msupsub">
                  <span class="vlist-t">
                   <span class="vlist-r">
                    <span class="vlist" style="height:0.8413em;">
                     <span style="top:-3.063em;margin-right:0.05em;">
                      <span class="pstrut" style="height:2.7em;">
                      </span>
                      <span class="sizing reset-size6 size3 mtight">
                       <span class="mord mtight">
                        <span class="mord text mtight">
                         <span class="mord mtight">
                          H
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
            .
where
            <span class="math">
             <span class="katex">
              <span class="katex-mathml">
               <math xmlns="http://www.w3.org/1998/Math/MathML">
                <semantics>
                 <mrow>
                  <msup>
                   <mi>
                    V
                   </mi>
                   <mtext>
                    H
                   </mtext>
                  </msup>
                 </mrow>
                 <annotation encoding="application/x-tex">
                  V^{\text{H}}
                 </annotation>
                </semantics>
               </math>
              </span>
              <span aria-hidden="true" class="katex-html">
               <span class="base">
                <span class="strut" style="height:0.8413em;">
                </span>
                <span class="mord">
                 <span class="mord mathnormal" style="margin-right:0.22222em;">
                  V
                 </span>
                 <span class="msupsub">
                  <span class="vlist-t">
                   <span class="vlist-r">
                    <span class="vlist" style="height:0.8413em;">
                     <span style="top:-3.063em;margin-right:0.05em;">
                      <span class="pstrut" style="height:2.7em;">
                      </span>
                      <span class="sizing reset-size6 size3 mtight">
                       <span class="mord mtight">
                        <span class="mord text mtight">
                         <span class="mord mtight">
                          H
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
            is the transpose of
            <cite>
             V
            </cite>
            for real inputs,
and the conjugate transpose of
            <cite>
             V
            </cite>
            for complex inputs.
If
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            is a batch of matrices, then
            <cite>
             U
            </cite>
            ,
            <cite>
             S
            </cite>
            , and
            <cite>
             V
            </cite>
            are also
batched with the same batch dimensions as
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            .
           </p>
           <p>
            If
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              some
             </span>
            </code>
            is
            <cite>
             True
            </cite>
            (default), the method returns the reduced singular
value decomposition. In this case, if the last two dimensions of
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            are
            <cite>
             m
            </cite>
            and
            <cite>
             n
            </cite>
            , then the returned
            <cite>
             U
            </cite>
            and
            <cite>
             V
            </cite>
            matrices will contain only
            <cite>
             min(n, m)
            </cite>
            orthonormal columns.
           </p>
           <p>
            If
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              compute_uv
             </span>
            </code>
            is
            <cite>
             False
            </cite>
            , the returned
            <cite>
             U
            </cite>
            and
            <cite>
             V
            </cite>
            will be
zero-filled matrices of shape
            <cite>
             (m, m)
            </cite>
            and
            <cite>
             (n, n)
            </cite>
            respectively, and the same device as
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            . The argument
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              some
             </span>
            </code>
            has no effect when
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              compute_uv
             </span>
            </code>
            is
            <cite>
             False
            </cite>
            .
           </p>
           <p>
            Supports
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            of float, double, cfloat and cdouble data types.
The dtypes of
            <cite>
             U
            </cite>
            and
            <cite>
             V
            </cite>
            are the same as
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            ’s.
            <cite>
             S
            </cite>
            will
always be real-valued, even if
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              input
             </span>
            </code>
            is complex.
           </p>
           <div class="admonition warning">
            <p class="admonition-title">
             Warning
            </p>
            <p>
             <a class="reference internal" href="#torch.svd" title="torch.svd">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.svd()
               </span>
              </code>
             </a>
             is deprecated in favor of
             <a class="reference internal" href="torch.linalg.svd.html#torch.linalg.svd" title="torch.linalg.svd">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.linalg.svd()
               </span>
              </code>
             </a>
             and will be removed in a future PyTorch release.
            </p>
            <p>
             <code class="docutils literal notranslate">
              <span class="pre">
               U,
              </span>
              <span class="pre">
               S,
              </span>
              <span class="pre">
               V
              </span>
              <span class="pre">
               =
              </span>
              <span class="pre">
               torch.svd(A,
              </span>
              <span class="pre">
               some=some,
              </span>
              <span class="pre">
               compute_uv=True)
              </span>
             </code>
             (default) should be replaced with
            </p>
            <div class="highlight-python notranslate">
             <div class="highlight">
              <pre><span></span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="ow">not</span> <span class="n">some</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">Vh</span><span class="o">.</span><span class="n">mH</span>
</pre>
             </div>
            </div>
            <p>
             <code class="docutils literal notranslate">
              <span class="pre">
               _,
              </span>
              <span class="pre">
               S,
              </span>
              <span class="pre">
               _
              </span>
              <span class="pre">
               =
              </span>
              <span class="pre">
               torch.svd(A,
              </span>
              <span class="pre">
               some=some,
              </span>
              <span class="pre">
               compute_uv=False)
              </span>
             </code>
             should be replaced with
            </p>
            <div class="highlight-python notranslate">
             <div class="highlight">
              <pre><span></span><span class="n">S</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre>
             </div>
            </div>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             Differences with
             <a class="reference internal" href="torch.linalg.svd.html#torch.linalg.svd" title="torch.linalg.svd">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.linalg.svd()
               </span>
              </code>
             </a>
             :
            </p>
            <ul class="simple">
             <li>
              <p>
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 some
                </span>
               </code>
               is the opposite of
               <a class="reference internal" href="torch.linalg.svd.html#torch.linalg.svd" title="torch.linalg.svd">
                <code class="xref py py-func docutils literal notranslate">
                 <span class="pre">
                  torch.linalg.svd()
                 </span>
                </code>
               </a>
               ’s
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 full_matrices
                </span>
               </code>
               . Note that
default value for both is
               <cite>
                True
               </cite>
               , so the default behavior is
effectively the opposite.
              </p>
             </li>
             <li>
              <p>
               <a class="reference internal" href="#torch.svd" title="torch.svd">
                <code class="xref py py-func docutils literal notranslate">
                 <span class="pre">
                  torch.svd()
                 </span>
                </code>
               </a>
               returns
               <cite>
                V
               </cite>
               , whereas
               <a class="reference internal" href="torch.linalg.svd.html#torch.linalg.svd" title="torch.linalg.svd">
                <code class="xref py py-func docutils literal notranslate">
                 <span class="pre">
                  torch.linalg.svd()
                 </span>
                </code>
               </a>
               returns
               <cite>
                Vh
               </cite>
               , that is,
               <span class="math">
                <span class="katex">
                 <span class="katex-mathml">
                  <math xmlns="http://www.w3.org/1998/Math/MathML">
                   <semantics>
                    <mrow>
                     <msup>
                      <mi>
                       V
                      </mi>
                      <mtext>
                       H
                      </mtext>
                     </msup>
                    </mrow>
                    <annotation encoding="application/x-tex">
                     V^{\text{H}}
                    </annotation>
                   </semantics>
                  </math>
                 </span>
                 <span aria-hidden="true" class="katex-html">
                  <span class="base">
                   <span class="strut" style="height:0.8413em;">
                   </span>
                   <span class="mord">
                    <span class="mord mathnormal" style="margin-right:0.22222em;">
                     V
                    </span>
                    <span class="msupsub">
                     <span class="vlist-t">
                      <span class="vlist-r">
                       <span class="vlist" style="height:0.8413em;">
                        <span style="top:-3.063em;margin-right:0.05em;">
                         <span class="pstrut" style="height:2.7em;">
                         </span>
                         <span class="sizing reset-size6 size3 mtight">
                          <span class="mord mtight">
                           <span class="mord text mtight">
                            <span class="mord mtight">
                             H
                            </span>
                           </span>
                          </span>
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
               .
              </p>
             </li>
             <li>
              <p>
               If
               <code class="xref py py-attr docutils literal notranslate">
                <span class="pre">
                 compute_uv
                </span>
               </code>
               is
               <cite>
                False
               </cite>
               ,
               <a class="reference internal" href="#torch.svd" title="torch.svd">
                <code class="xref py py-func docutils literal notranslate">
                 <span class="pre">
                  torch.svd()
                 </span>
                </code>
               </a>
               returns zero-filled
tensors for
               <cite>
                U
               </cite>
               and
               <cite>
                Vh
               </cite>
               , whereas
               <a class="reference internal" href="torch.linalg.svd.html#torch.linalg.svd" title="torch.linalg.svd">
                <code class="xref py py-func docutils literal notranslate">
                 <span class="pre">
                  torch.linalg.svd()
                 </span>
                </code>
               </a>
               returns
empty tensors.
              </p>
             </li>
            </ul>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             The singular values are returned in descending order. If
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               input
              </span>
             </code>
             is a batch of matrices,
then the singular values of each matrix in the batch are returned in descending order.
            </p>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             The
             <cite>
              S
             </cite>
             tensor can only be used to compute gradients if
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               compute_uv
              </span>
             </code>
             is
             <cite>
              True
             </cite>
             .
            </p>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             When
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               some
              </span>
             </code>
             is
             <cite>
              False
             </cite>
             , the gradients on
             <cite>
              U[…, :, min(m, n):]
             </cite>
             and
             <cite>
              V[…, :, min(m, n):]
             </cite>
             will be ignored in the backward pass, as those vectors
can be arbitrary bases of the corresponding subspaces.
            </p>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             The implementation of
             <a class="reference internal" href="torch.linalg.svd.html#torch.linalg.svd" title="torch.linalg.svd">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.linalg.svd()
               </span>
              </code>
             </a>
             on CPU uses LAPACK’s routine
             <cite>
              ?gesdd
             </cite>
             (a divide-and-conquer algorithm) instead of
             <cite>
              ?gesvd
             </cite>
             for speed. Analogously,
on GPU, it uses cuSOLVER’s routines
             <cite>
              gesvdj
             </cite>
             and
             <cite>
              gesvdjBatched
             </cite>
             on CUDA 10.1.243
and later, and MAGMA’s routine
             <cite>
              gesdd
             </cite>
             on earlier versions of CUDA.
            </p>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             The returned
             <cite>
              U
             </cite>
             will not be contiguous. The matrix (or batch of matrices) will
be represented as a column-major matrix (i.e. Fortran-contiguous).
            </p>
           </div>
           <div class="admonition warning">
            <p class="admonition-title">
             Warning
            </p>
            <p>
             The gradients with respect to
             <cite>
              U
             </cite>
             and
             <cite>
              V
             </cite>
             will only be finite when the input does not
have zero nor repeated singular values.
            </p>
           </div>
           <div class="admonition warning">
            <p class="admonition-title">
             Warning
            </p>
            <p>
             If the distance between any two singular values is close to zero, the gradients with respect to
             <cite>
              U
             </cite>
             and
             <cite>
              V
             </cite>
             will be numerically unstable, as they depends on
             <span class="math">
              <span class="katex">
               <span class="katex-mathml">
                <math xmlns="http://www.w3.org/1998/Math/MathML">
                 <semantics>
                  <mrow>
                   <mfrac>
                    <mn>
                     1
                    </mn>
                    <mrow>
                     <msub>
                      <mrow>
                       <mi>
                        min
                       </mi>
                       <mo>
                        ⁡
                       </mo>
                      </mrow>
                      <mrow>
                       <mi>
                        i
                       </mi>
                       <mo mathvariant="normal">
                        ≠
                       </mo>
                       <mi>
                        j
                       </mi>
                      </mrow>
                     </msub>
                     <msubsup>
                      <mi>
                       σ
                      </mi>
                      <mi>
                       i
                      </mi>
                      <mn>
                       2
                      </mn>
                     </msubsup>
                     <mo>
                      −
                     </mo>
                     <msubsup>
                      <mi>
                       σ
                      </mi>
                      <mi>
                       j
                      </mi>
                      <mn>
                       2
                      </mn>
                     </msubsup>
                    </mrow>
                   </mfrac>
                  </mrow>
                  <annotation encoding="application/x-tex">
                   \frac{1}{\min_{i \neq j} \sigma_i^2 - \sigma_j^2}
                  </annotation>
                 </semantics>
                </math>
               </span>
               <span aria-hidden="true" class="katex-html">
                <span class="base">
                 <span class="strut" style="height:1.5415em;vertical-align:-0.6964em;">
                 </span>
                 <span class="mord">
                  <span class="mopen nulldelimiter">
                  </span>
                  <span class="mfrac">
                   <span class="vlist-t vlist-t2">
                    <span class="vlist-r">
                     <span class="vlist" style="height:0.8451em;">
                      <span style="top:-2.6264em;">
                       <span class="pstrut" style="height:3em;">
                       </span>
                       <span class="sizing reset-size6 size3 mtight">
                        <span class="mord mtight">
                         <span class="mop mtight">
                          <span class="mop mtight">
                           <span class="mtight">
                            m
                           </span>
                           <span class="mtight">
                            i
                           </span>
                           <span class="mtight">
                            n
                           </span>
                          </span>
                          <span class="msupsub">
                           <span class="vlist-t vlist-t2">
                            <span class="vlist-r">
                             <span class="vlist" style="height:0.3448em;">
                              <span style="top:-2.3488em;margin-right:0.0714em;">
                               <span class="pstrut" style="height:2.5em;">
                               </span>
                               <span class="sizing reset-size3 size1 mtight">
                                <span class="mord mtight">
                                 <span class="mord mathnormal mtight">
                                  i
                                 </span>
                                 <span class="mrel mtight">
                                  <span class="mrel mtight">
                                   <span class="mord vbox mtight">
                                    <span class="thinbox mtight">
                                     <span class="rlap mtight">
                                      <span class="strut" style="height:0.8889em;vertical-align:-0.1944em;">
                                      </span>
                                      <span class="inner">
                                       <span class="mord mtight">
                                        <span class="mrel mtight">
                                         
                                        </span>
                                       </span>
                                      </span>
                                      <span class="fix">
                                      </span>
                                     </span>
                                    </span>
                                   </span>
                                  </span>
                                  <span class="mrel mtight">
                                   =
                                  </span>
                                 </span>
                                 <span class="mord mathnormal mtight" style="margin-right:0.05724em;">
                                  j
                                 </span>
                                </span>
                               </span>
                              </span>
                             </span>
                             <span class="vlist-s">
                              ​
                             </span>
                            </span>
                            <span class="vlist-r">
                             <span class="vlist" style="height:0.2901em;">
                              <span>
                              </span>
                             </span>
                            </span>
                           </span>
                          </span>
                         </span>
                         <span class="mspace mtight" style="margin-right:0.1952em;">
                         </span>
                         <span class="mord mtight">
                          <span class="mord mathnormal mtight" style="margin-right:0.03588em;">
                           σ
                          </span>
                          <span class="msupsub">
                           <span class="vlist-t vlist-t2">
                            <span class="vlist-r">
                             <span class="vlist" style="height:0.8051em;">
                              <span style="top:-2.1777em;margin-left:-0.0359em;margin-right:0.0714em;">
                               <span class="pstrut" style="height:2.5em;">
                               </span>
                               <span class="sizing reset-size3 size1 mtight">
                                <span class="mord mathnormal mtight">
                                 i
                                </span>
                               </span>
                              </span>
                              <span style="top:-2.8448em;margin-right:0.0714em;">
                               <span class="pstrut" style="height:2.5em;">
                               </span>
                               <span class="sizing reset-size3 size1 mtight">
                                <span class="mord mtight">
                                 2
                                </span>
                               </span>
                              </span>
                             </span>
                             <span class="vlist-s">
                              ​
                             </span>
                            </span>
                            <span class="vlist-r">
                             <span class="vlist" style="height:0.3223em;">
                              <span>
                              </span>
                             </span>
                            </span>
                           </span>
                          </span>
                         </span>
                         <span class="mbin mtight">
                          −
                         </span>
                         <span class="mord mtight">
                          <span class="mord mathnormal mtight" style="margin-right:0.03588em;">
                           σ
                          </span>
                          <span class="msupsub">
                           <span class="vlist-t vlist-t2">
                            <span class="vlist-r">
                             <span class="vlist" style="height:0.8051em;">
                              <span style="top:-2.1777em;margin-left:-0.0359em;margin-right:0.0714em;">
                               <span class="pstrut" style="height:2.5em;">
                               </span>
                               <span class="sizing reset-size3 size1 mtight">
                                <span class="mord mathnormal mtight" style="margin-right:0.05724em;">
                                 j
                                </span>
                               </span>
                              </span>
                              <span style="top:-2.8448em;margin-right:0.0714em;">
                               <span class="pstrut" style="height:2.5em;">
                               </span>
                               <span class="sizing reset-size3 size1 mtight">
                                <span class="mord mtight">
                                 2
                                </span>
                               </span>
                              </span>
                             </span>
                             <span class="vlist-s">
                              ​
                             </span>
                            </span>
                            <span class="vlist-r">
                             <span class="vlist" style="height:0.4612em;">
                              <span>
                              </span>
                             </span>
                            </span>
                           </span>
                          </span>
                         </span>
                        </span>
                       </span>
                      </span>
                      <span style="top:-3.23em;">
                       <span class="pstrut" style="height:3em;">
                       </span>
                       <span class="frac-line" style="border-bottom-width:0.04em;">
                       </span>
                      </span>
                      <span style="top:-3.394em;">
                       <span class="pstrut" style="height:3em;">
                       </span>
                       <span class="sizing reset-size6 size3 mtight">
                        <span class="mord mtight">
                         <span class="mord mtight">
                          1
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                     <span class="vlist-s">
                      ​
                     </span>
                    </span>
                    <span class="vlist-r">
                     <span class="vlist" style="height:0.6964em;">
                      <span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                  <span class="mclose nulldelimiter">
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
             . The same happens when the matrix
has small singular values, as these gradients also depend on
             <cite>
              S⁻¹
             </cite>
             .
            </p>
           </div>
           <div class="admonition warning">
            <p class="admonition-title">
             Warning
            </p>
            <p>
             For complex-valued
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               input
              </span>
             </code>
             the singular value decomposition is not unique,
as
             <cite>
              U
             </cite>
             and
             <cite>
              V
             </cite>
             may be multiplied by an arbitrary phase factor
             <span class="math">
              <span class="katex">
               <span class="katex-mathml">
                <math xmlns="http://www.w3.org/1998/Math/MathML">
                 <semantics>
                  <mrow>
                   <msup>
                    <mi>
                     e
                    </mi>
                    <mrow>
                     <mi>
                      i
                     </mi>
                     <mi>
                      ϕ
                     </mi>
                    </mrow>
                   </msup>
                  </mrow>
                  <annotation encoding="application/x-tex">
                   e^{i \phi}
                  </annotation>
                 </semantics>
                </math>
               </span>
               <span aria-hidden="true" class="katex-html">
                <span class="base">
                 <span class="strut" style="height:0.8491em;">
                 </span>
                 <span class="mord">
                  <span class="mord mathnormal">
                   e
                  </span>
                  <span class="msupsub">
                   <span class="vlist-t">
                    <span class="vlist-r">
                     <span class="vlist" style="height:0.8491em;">
                      <span style="top:-3.063em;margin-right:0.05em;">
                       <span class="pstrut" style="height:2.7em;">
                       </span>
                       <span class="sizing reset-size6 size3 mtight">
                        <span class="mord mtight">
                         <span class="mord mathnormal mtight">
                          i
                         </span>
                         <span class="mord mathnormal mtight">
                          ϕ
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
             on every column.
The same happens when
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               input
              </span>
             </code>
             has repeated singular values, where one may multiply
the columns of the spanning subspace in
             <cite>
              U
             </cite>
             and
             <cite>
              V
             </cite>
             by a rotation matrix
and
             <a class="reference external" href="(https://en.wikipedia.org/wiki/Singular_value_decomposition#Singular_values,_singular_vectors,_and_their_relation_to_the_SVD)">
              the resulting vectors will span the same subspace
             </a>
             .
Different platforms, like NumPy, or inputs on different device types,
may produce different
             <cite>
              U
             </cite>
             and
             <cite>
              V
             </cite>
             tensors.
            </p>
           </div>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 input
                </strong>
                (
                <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
                 <em>
                  Tensor
                 </em>
                </a>
                ) – the input tensor of size
                <cite>
                 (*, m, n)
                </cite>
                where
                <cite>
                 *
                </cite>
                is zero or more
batch dimensions consisting of
                <cite>
                 (m, n)
                </cite>
                matrices.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 some
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – controls whether to compute the reduced or full decomposition, and
consequently, the shape of returned
                <cite>
                 U
                </cite>
                and
                <cite>
                 V
                </cite>
                . Default:
                <cite>
                 True
                </cite>
                .
               </p>
              </li>
              <li>
               <p>
                <strong>
                 compute_uv
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – controls whether to compute
                <cite>
                 U
                </cite>
                and
                <cite>
                 V
                </cite>
                . Default:
                <cite>
                 True
                </cite>
                .
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <p>
              <strong>
               out
              </strong>
              (
              <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.10)">
               <em>
                tuple
               </em>
              </a>
              <em>
               ,
              </em>
              <em>
               optional
              </em>
              ) – the output tuple of tensors
             </p>
            </dd>
           </dl>
           <p>
            Example:
           </p>
           <div class="highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[ 0.2364, -0.7752,  0.6372],</span>
<span class="go">        [ 1.7201,  0.7394, -0.0504],</span>
<span class="go">        [-0.3371, -1.0584,  0.5296],</span>
<span class="go">        [ 0.3550, -0.4022,  1.5569],</span>
<span class="go">        [ 0.2445, -0.0158,  1.1414]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>
<span class="go">tensor([[ 0.4027,  0.0287,  0.5434],</span>
<span class="go">        [-0.1946,  0.8833,  0.3679],</span>
<span class="go">        [ 0.4296, -0.2890,  0.5261],</span>
<span class="go">        [ 0.6604,  0.2717, -0.2618],</span>
<span class="go">        [ 0.4234,  0.2481, -0.4733]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span>
<span class="go">tensor([2.3289, 2.0315, 0.7806])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>
<span class="go">tensor([[-0.0199,  0.8766,  0.4809],</span>
<span class="go">        [-0.5080,  0.4054, -0.7600],</span>
<span class="go">        [ 0.8611,  0.2594, -0.4373]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)),</span> <span class="n">v</span><span class="o">.</span><span class="n">t</span><span class="p">()))</span>
<span class="go">tensor(8.6531e-07)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_big</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a_big</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">a_big</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">s</span><span class="p">)),</span> <span class="n">v</span><span class="o">.</span><span class="n">mT</span><span class="p">))</span>
<span class="go">tensor(2.6503e-06)</span>
</pre>
            </div>
           </div>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>