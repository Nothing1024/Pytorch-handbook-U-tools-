<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.fft.rfftfreq — PyTorch 1.11.0 documentation
  </title>
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- End Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="torch-fft-rfftfreq">
         <h1>
          torch.fft.rfftfreq
          <a class="headerlink" href="#torch-fft-rfftfreq" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py function">
          <dt id="torch.fft.rfftfreq">
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.fft.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             rfftfreq
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              n
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              d
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              1.0
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="o">
             <span class="pre">
              *
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              out
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              dtype
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              layout
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              torch.strided
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              device
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              requires_grad
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              False
             </span>
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           →
           <span class="pre">
            Tensor
           </span>
           <a class="headerlink" href="#torch.fft.rfftfreq" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Computes the sample frequencies for
            <a class="reference internal" href="torch.fft.rfft.html#torch.fft.rfft" title="torch.fft.rfft">
             <code class="xref py py-func docutils literal notranslate">
              <span class="pre">
               rfft()
              </span>
             </code>
            </a>
            with a signal of size
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              n
             </span>
            </code>
            .
           </p>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             <a class="reference internal" href="torch.fft.rfft.html#torch.fft.rfft" title="torch.fft.rfft">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                rfft()
               </span>
              </code>
             </a>
             returns Hermitian one-sided output, so only the
positive frequency terms are returned. For a real FFT of length
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               n
              </span>
             </code>
             and with inputs spaced in length unit
             <code class="xref py py-attr docutils literal notranslate">
              <span class="pre">
               d
              </span>
             </code>
             , the frequencies are:
            </p>
            <div class="highlight-default notranslate">
             <div class="highlight">
              <pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">d</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span>
</pre>
             </div>
            </div>
           </div>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             For even lengths, the Nyquist frequency at
             <code class="docutils literal notranslate">
              <span class="pre">
               f[n/2]
              </span>
             </code>
             can be thought of as
either negative or positive. Unlike
             <a class="reference internal" href="torch.fft.fftfreq.html#torch.fft.fftfreq" title="torch.fft.fftfreq">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                fftfreq()
               </span>
              </code>
             </a>
             ,
             <a class="reference internal" href="#torch.fft.rfftfreq" title="torch.fft.rfftfreq">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                rfftfreq()
               </span>
              </code>
             </a>
             always returns it as positive.
            </p>
           </div>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 n
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                 <em>
                  int
                 </em>
                </a>
                ) – the real FFT length
               </p>
              </li>
              <li>
               <p>
                <strong>
                 d
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)">
                 <em>
                  float
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – The sampling length scale.
The spacing between individual samples of the FFT input.
The default assumes unit spacing, dividing that result by the actual
spacing gives the result in physical frequency units.
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 out
                </strong>
                (
                <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
                 <em>
                  Tensor
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – the output tensor.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 dtype
                </strong>
                (
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.dtype
                 </span>
                </code>
                , optional) – the desired data type of returned tensor.
Default: if
                <code class="docutils literal notranslate">
                 <span class="pre">
                  None
                 </span>
                </code>
                , uses a global default (see
                <a class="reference internal" href="torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type">
                 <code class="xref py py-func docutils literal notranslate">
                  <span class="pre">
                   torch.set_default_tensor_type()
                  </span>
                 </code>
                </a>
                ).
               </p>
              </li>
              <li>
               <p>
                <strong>
                 layout
                </strong>
                (
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.layout
                 </span>
                </code>
                , optional) – the desired layout of returned Tensor.
Default:
                <code class="docutils literal notranslate">
                 <span class="pre">
                  torch.strided
                 </span>
                </code>
                .
               </p>
              </li>
              <li>
               <p>
                <strong>
                 device
                </strong>
                (
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  torch.device
                 </span>
                </code>
                , optional) – the desired device of returned tensor.
Default: if
                <code class="docutils literal notranslate">
                 <span class="pre">
                  None
                 </span>
                </code>
                , uses the current device for the default tensor type
(see
                <a class="reference internal" href="torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type">
                 <code class="xref py py-func docutils literal notranslate">
                  <span class="pre">
                   torch.set_default_tensor_type()
                  </span>
                 </code>
                </a>
                ).
                <code class="xref py py-attr docutils literal notranslate">
                 <span class="pre">
                  device
                 </span>
                </code>
                will be the CPU
for CPU tensor types and the current CUDA device for CUDA tensor types.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 requires_grad
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – If autograd should record operations on the
returned tensor. Default:
                <code class="docutils literal notranslate">
                 <span class="pre">
                  False
                 </span>
                </code>
                .
               </p>
              </li>
             </ul>
            </dd>
           </dl>
           <p class="rubric">
            Example
           </p>
           <div class="doctest highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftfreq</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="go">tensor([0.0000, 0.2000, 0.4000])</span>
</pre>
            </div>
           </div>
           <div class="doctest highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftfreq</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="go">tensor([0.0000, 0.2500, 0.5000])</span>
</pre>
            </div>
           </div>
           <p>
            Compared to the output from
            <a class="reference internal" href="torch.fft.fftfreq.html#torch.fft.fftfreq" title="torch.fft.fftfreq">
             <code class="xref py py-func docutils literal notranslate">
              <span class="pre">
               fftfreq()
              </span>
             </code>
            </a>
            , we see that the
Nyquist frequency at
            <code class="docutils literal notranslate">
             <span class="pre">
              f[2]
             </span>
            </code>
            has changed sign:
&gt;&gt;&gt; torch.fft.fftfreq(4)
tensor([ 0.0000,  0.2500, -0.5000, -0.2500])
           </p>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>