<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   SequentialLR — PyTorch 1.10 documentation
  </title>
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="sequentiallr">
         <h1>
          SequentialLR
          <a class="headerlink" href="#sequentiallr" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py class">
          <dt id="torch.optim.lr_scheduler.SequentialLR">
           <em class="property">
            <span class="pre">
             class
            </span>
           </em>
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.optim.lr_scheduler.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             SequentialLR
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              optimizer
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              schedulers
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              milestones
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              last_epoch
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              -
             </span>
             <span class="pre">
              1
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              verbose
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              False
             </span>
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="reference internal" href="../_modules/torch/optim/lr_scheduler.html#SequentialLR">
            <span class="viewcode-link">
             <span class="pre">
              [source]
             </span>
            </span>
           </a>
           <a class="headerlink" href="#torch.optim.lr_scheduler.SequentialLR" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Receives the list of schedulers that is expected to be called sequentially during
optimization process and milestone points that provides exact intervals to reflect
which scheduler is supposed to be called at a given epoch.
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 schedulers
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)">
                 <em>
                  list
                 </em>
                </a>
                ) – List of chained schedulers.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 milestones
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)">
                 <em>
                  list
                 </em>
                </a>
                ) – List of integers that reflects milestone points.
               </p>
              </li>
             </ul>
            </dd>
           </dl>
           <p class="rubric">
            Example
           </p>
           <div class="doctest highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Assuming optimizer uses lr = 1. for all groups</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.1     if epoch == 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.1     if epoch == 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.9     if epoch == 2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.81    if epoch == 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.729   if epoch == 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler1</span> <span class="o">=</span> <span class="n">ConstantLR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">total_iters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler2</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">SequentialLR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler1</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">],</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre>
            </div>
           </div>
           <dl class="py method">
            <dt id="torch.optim.lr_scheduler.SequentialLR.get_last_lr">
             <code class="sig-name descname">
              <span class="pre">
               get_last_lr
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="headerlink" href="#torch.optim.lr_scheduler.SequentialLR.get_last_lr" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Return last computed learning rate by current scheduler.
             </p>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.optim.lr_scheduler.SequentialLR.load_state_dict">
             <code class="sig-name descname">
              <span class="pre">
               load_state_dict
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                state_dict
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/optim/lr_scheduler.html#SequentialLR.load_state_dict">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.optim.lr_scheduler.SequentialLR.load_state_dict" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Loads the schedulers state.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 state_dict
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.10)">
                 <em>
                  dict
                 </em>
                </a>
                ) – scheduler state. Should be an object returned
from a call to
                <a class="reference internal" href="#torch.optim.lr_scheduler.SequentialLR.state_dict" title="torch.optim.lr_scheduler.SequentialLR.state_dict">
                 <code class="xref py py-meth docutils literal notranslate">
                  <span class="pre">
                   state_dict()
                  </span>
                 </code>
                </a>
                .
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.optim.lr_scheduler.SequentialLR.print_lr">
             <code class="sig-name descname">
              <span class="pre">
               print_lr
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                is_verbose
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                group
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                lr
               </span>
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="n">
               <span class="pre">
                epoch
               </span>
              </span>
              <span class="o">
               <span class="pre">
                =
               </span>
              </span>
              <span class="default_value">
               <span class="pre">
                None
               </span>
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="headerlink" href="#torch.optim.lr_scheduler.SequentialLR.print_lr" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Display the current learning rate.
             </p>
            </dd>
           </dl>
           <dl class="py method">
            <dt id="torch.optim.lr_scheduler.SequentialLR.state_dict">
             <code class="sig-name descname">
              <span class="pre">
               state_dict
              </span>
             </code>
             <span class="sig-paren">
              (
             </span>
             <span class="sig-paren">
              )
             </span>
             <a class="reference internal" href="../_modules/torch/optim/lr_scheduler.html#SequentialLR.state_dict">
              <span class="viewcode-link">
               <span class="pre">
                [source]
               </span>
              </span>
             </a>
             <a class="headerlink" href="#torch.optim.lr_scheduler.SequentialLR.state_dict" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Returns the state of the scheduler as a
              <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.10)">
               <code class="xref py py-class docutils literal notranslate">
                <span class="pre">
                 dict
                </span>
               </code>
              </a>
              .
             </p>
             <p>
              It contains an entry for every variable in self.__dict__ which
is not the optimizer.
The wrapped scheduler states will also be saved.
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>