<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.linalg.lu_factor — PyTorch 1.12 documentation
  </title>
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- End Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="torch-linalg-lu-factor">
         <h1>
          torch.linalg.lu_factor
          <a class="headerlink" href="#torch-linalg-lu-factor" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <dl class="py function">
          <dt id="torch.linalg.lu_factor">
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.linalg.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             lu_factor
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="pre">
             A
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             *
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             bool
            </span>
            <span class="pre">
             pivot=True
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             out=None)
            </span>
            <span class="pre">
             -&gt;
            </span>
            <span class="pre">
             (Tensor
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="pre">
             Tensor
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="headerlink" href="#torch.linalg.lu_factor" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Computes a compact representation of the LU factorization with partial pivoting of a matrix.
           </p>
           <p>
            This function computes a compact representation of the decomposition given by
            <a class="reference internal" href="torch.linalg.lu.html#torch.linalg.lu" title="torch.linalg.lu">
             <code class="xref py py-func docutils literal notranslate">
              <span class="pre">
               torch.linalg.lu()
              </span>
             </code>
            </a>
            .
If the matrix is square, this representation may be used in
            <code class="xref py py-func docutils literal notranslate">
             <span class="pre">
              torch.linalg.lu_solve()
             </span>
            </code>
            to solve system of linear equations that share the matrix
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              A
             </span>
            </code>
            .
           </p>
           <p>
            The returned decomposition is represented as a named tuple
            <cite>
             (LU, pivots)
            </cite>
            .
The
            <code class="docutils literal notranslate">
             <span class="pre">
              LU
             </span>
            </code>
            matrix has the same shape as the input matrix
            <code class="docutils literal notranslate">
             <span class="pre">
              A
             </span>
            </code>
            . Its upper and lower triangular
parts encode the non-constant elements of
            <code class="docutils literal notranslate">
             <span class="pre">
              L
             </span>
            </code>
            and
            <code class="docutils literal notranslate">
             <span class="pre">
              U
             </span>
            </code>
            of the LU decomposition of
            <code class="docutils literal notranslate">
             <span class="pre">
              A
             </span>
            </code>
            .
           </p>
           <p>
            The returned permutation matrix is represented by a 1-indexed vector.
            <cite>
             pivots[i] == j
            </cite>
            represents
that in the
            <cite>
             i
            </cite>
            -th step of the algorithm, the
            <cite>
             i
            </cite>
            -th row was permuted with the
            <cite>
             j-1
            </cite>
            -th row.
           </p>
           <p>
            On CUDA, one may use
            <code class="xref py py-attr docutils literal notranslate">
             <span class="pre">
              pivot
             </span>
            </code>
            <cite>
             = False
            </cite>
            . In this case, this function returns the LU
decomposition without pivoting if it exists.
           </p>
           <p>
            Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions.
           </p>
           <div class="admonition note">
            <p class="admonition-title">
             Note
            </p>
            <p>
             When inputs are on a CUDA device, this function synchronizes that device with the CPU. For a version of this function that does not synchronize, see
             <a class="reference internal" href="torch.linalg.lu_factor_ex.html#torch.linalg.lu_factor_ex" title="torch.linalg.lu_factor_ex">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.linalg.lu_factor_ex()
               </span>
              </code>
             </a>
             .
            </p>
           </div>
           <div class="admonition warning">
            <p class="admonition-title">
             Warning
            </p>
            <p>
             The LU decomposition is almost never unique, as often there are different permutation
matrices that can yield different LU decompositions.
As such, different platforms, like SciPy, or inputs on different devices,
may produce different valid decompositions.
            </p>
            <p>
             Gradient computations are only supported if the input matrix is full-rank.
If this condition is not met, no error will be thrown, but the gradient may not be finite.
This is because the LU decomposition with pivoting is not differentiable at these points.
            </p>
           </div>
           <div class="admonition seealso">
            <p class="admonition-title">
             See also
            </p>
            <p>
             <code class="xref py py-func docutils literal notranslate">
              <span class="pre">
               torch.linalg.lu_solve()
              </span>
             </code>
             solves a system of linear equations given the output of this
function provided the input matrix was square and invertible.
            </p>
            <p>
             <a class="reference internal" href="torch.linalg.lu.html#torch.linalg.lu" title="torch.linalg.lu">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.linalg.lu()
               </span>
              </code>
             </a>
             computes the LU decomposition with partial pivoting of a possibly
non-square matrix.
            </p>
            <p>
             <a class="reference internal" href="torch.linalg.solve.html#torch.linalg.solve" title="torch.linalg.solve">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.linalg.solve()
               </span>
              </code>
             </a>
             solves a system of linear equations. It is a composition
of
             <a class="reference internal" href="#torch.linalg.lu_factor" title="torch.linalg.lu_factor">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                lu_factor()
               </span>
              </code>
             </a>
             and
             <code class="xref py py-func docutils literal notranslate">
              <span class="pre">
               lu_solve()
              </span>
             </code>
             .
            </p>
           </div>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <p>
              <strong>
               A
              </strong>
              (
              <a class="reference internal" href="../tensors.html#torch.Tensor" title="torch.Tensor">
               <em>
                Tensor
               </em>
              </a>
              ) – tensor of shape
              <cite>
               (*, m, n)
              </cite>
              where
              <cite>
               *
              </cite>
              is zero or more batch dimensions.
             </p>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 pivot
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
                 <em>
                  bool
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – Whether to compute the LU decomposition with partial pivoting, or the regular LU
decomposition.
                <code class="xref py py-attr docutils literal notranslate">
                 <span class="pre">
                  pivot
                 </span>
                </code>
                <cite>
                 = False
                </cite>
                not supported on CPU. Default:
                <cite>
                 True
                </cite>
                .
               </p>
              </li>
              <li>
               <p>
                <strong>
                 out
                </strong>
                (
                <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.10)">
                 <em>
                  tuple
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – tuple of two tensors to write the output to. Ignored if
                <cite>
                 None
                </cite>
                . Default:
                <cite>
                 None
                </cite>
                .
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-odd">
             Returns
            </dt>
            <dd class="field-odd">
             <p>
              A named tuple
              <cite>
               (LU, pivots)
              </cite>
              .
             </p>
            </dd>
            <dt class="field-even">
             Raises
            </dt>
            <dd class="field-even">
             <p>
              <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.10)">
               <strong>
                RuntimeError
               </strong>
              </a>
              – if the
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                A
               </span>
              </code>
              matrix is not invertible or any matrix in a batched
              <code class="xref py py-attr docutils literal notranslate">
               <span class="pre">
                A
               </span>
              </code>
              is not invertible.
             </p>
            </dd>
           </dl>
           <p>
            Examples:
           </p>
           <div class="highlight-default notranslate">
            <div class="highlight">
             <pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_factor</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">(</span><span class="n">A_factor</span><span class="p">,</span> <span class="n">B1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">(</span><span class="n">A_factor</span><span class="p">,</span> <span class="n">B2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">X1</span><span class="p">,</span> <span class="n">B1</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">X2</span><span class="p">,</span> <span class="n">B2</span><span class="p">)</span>
<span class="go">True</span>
</pre>
            </div>
           </div>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>