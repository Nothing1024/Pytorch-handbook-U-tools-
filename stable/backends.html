<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.backends — PyTorch 1.10 documentation
  </title>
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="torch-backends">
         <h1>
          torch.backends
          <a class="headerlink" href="#torch-backends" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <p>
          <cite>
           torch.backends
          </cite>
          controls the behavior of various backends that PyTorch supports.
         </p>
         <p>
          These backends include:
         </p>
         <ul class="simple">
          <li>
           <p>
            <code class="docutils literal notranslate">
             <span class="pre">
              torch.backends.cuda
             </span>
            </code>
           </p>
          </li>
          <li>
           <p>
            <code class="docutils literal notranslate">
             <span class="pre">
              torch.backends.cudnn
             </span>
            </code>
           </p>
          </li>
          <li>
           <p>
            <code class="docutils literal notranslate">
             <span class="pre">
              torch.backends.mkl
             </span>
            </code>
           </p>
          </li>
          <li>
           <p>
            <code class="docutils literal notranslate">
             <span class="pre">
              torch.backends.mkldnn
             </span>
            </code>
           </p>
          </li>
          <li>
           <p>
            <code class="docutils literal notranslate">
             <span class="pre">
              torch.backends.openmp
             </span>
            </code>
           </p>
          </li>
         </ul>
         <div class="section" id="torch-backends-cuda">
          <h2>
           torch.backends.cuda
           <a class="headerlink" href="#torch-backends-cuda" title="Permalink to this headline">
            ¶
           </a>
          </h2>
          <dl class="py function">
           <dt id="torch.backends.cuda.is_built">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cuda.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              is_built
             </span>
            </code>
            <span class="sig-paren">
             (
            </span>
            <span class="sig-paren">
             )
            </span>
            <a class="reference internal" href="_modules/torch/backends/cuda.html#is_built">
             <span class="viewcode-link">
              <span class="pre">
               [source]
              </span>
             </span>
            </a>
            <a class="headerlink" href="#torch.backends.cuda.is_built" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             Returns whether PyTorch is built with CUDA support.  Note that this
doesn’t necessarily mean CUDA is available; just that if this PyTorch
binary were run a machine with working CUDA drivers and devices, we
would be able to use it.
            </p>
           </dd>
          </dl>
          <dl class="py attribute">
           <dt id="torch.backends.cuda.matmul.allow_tf32">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cuda.matmul.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              allow_tf32
             </span>
            </code>
            <a class="headerlink" href="#torch.backends.cuda.matmul.allow_tf32" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             A
             <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                bool
               </span>
              </code>
             </a>
             that controls whether TensorFloat-32 tensor cores may be used in matrix
multiplications on Ampere or newer GPUs. See
             <a class="reference internal" href="notes/cuda.html#tf32-on-ampere">
              <span class="std std-ref">
               TensorFloat-32(TF32) on Ampere devices
              </span>
             </a>
             .
            </p>
           </dd>
          </dl>
          <dl class="py attribute">
           <dt id="torch.backends.cuda.cufft_plan_cache">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cuda.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              cufft_plan_cache
             </span>
            </code>
            <a class="headerlink" href="#torch.backends.cuda.cufft_plan_cache" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             <code class="docutils literal notranslate">
              <span class="pre">
               cufft_plan_cache
              </span>
             </code>
             caches the cuFFT plans
            </p>
            <dl class="py attribute">
             <dt id="torch.backends.cuda.size">
              <code class="sig-name descname">
               <span class="pre">
                size
               </span>
              </code>
              <a class="headerlink" href="#torch.backends.cuda.size" title="Permalink to this definition">
               ¶
              </a>
             </dt>
             <dd>
              <p>
               A readonly
               <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  int
                 </span>
                </code>
               </a>
               that shows the number of plans currently in the cuFFT plan cache.
              </p>
             </dd>
            </dl>
            <dl class="py attribute">
             <dt id="max_size">
              <code class="sig-name descname">
               <span class="pre">
                max_size
               </span>
              </code>
              <a class="headerlink" href="#max_size" title="Permalink to this definition">
               ¶
              </a>
             </dt>
             <dd>
              <p>
               A
               <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">
                <code class="xref py py-class docutils literal notranslate">
                 <span class="pre">
                  int
                 </span>
                </code>
               </a>
               that controls cache capacity of cuFFT plan.
              </p>
             </dd>
            </dl>
            <dl class="py method">
             <dt id="clear">
              <code class="sig-name descname">
               <span class="pre">
                clear
               </span>
              </code>
              <span class="sig-paren">
               (
              </span>
              <span class="sig-paren">
               )
              </span>
              <a class="headerlink" href="#clear" title="Permalink to this definition">
               ¶
              </a>
             </dt>
             <dd>
              <p>
               Clears the cuFFT plan cache.
              </p>
             </dd>
            </dl>
           </dd>
          </dl>
         </div>
         <div class="section" id="torch-backends-cudnn">
          <h2>
           torch.backends.cudnn
           <a class="headerlink" href="#torch-backends-cudnn" title="Permalink to this headline">
            ¶
           </a>
          </h2>
          <dl class="py function">
           <dt id="torch.backends.cudnn.version">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cudnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              version
             </span>
            </code>
            <span class="sig-paren">
             (
            </span>
            <span class="sig-paren">
             )
            </span>
            <a class="reference internal" href="_modules/torch/backends/cudnn.html#version">
             <span class="viewcode-link">
              <span class="pre">
               [source]
              </span>
             </span>
            </a>
            <a class="headerlink" href="#torch.backends.cudnn.version" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             Returns the version of cuDNN
            </p>
           </dd>
          </dl>
          <dl class="py function">
           <dt id="torch.backends.cudnn.is_available">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cudnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              is_available
             </span>
            </code>
            <span class="sig-paren">
             (
            </span>
            <span class="sig-paren">
             )
            </span>
            <a class="reference internal" href="_modules/torch/backends/cudnn.html#is_available">
             <span class="viewcode-link">
              <span class="pre">
               [source]
              </span>
             </span>
            </a>
            <a class="headerlink" href="#torch.backends.cudnn.is_available" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             Returns a bool indicating if CUDNN is currently available.
            </p>
           </dd>
          </dl>
          <dl class="py attribute">
           <dt id="torch.backends.cudnn.enabled">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cudnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              enabled
             </span>
            </code>
            <a class="headerlink" href="#torch.backends.cudnn.enabled" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             A
             <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                bool
               </span>
              </code>
             </a>
             that controls whether cuDNN is enabled.
            </p>
           </dd>
          </dl>
          <dl class="py attribute">
           <dt id="torch.backends.cudnn.allow_tf32">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cudnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              allow_tf32
             </span>
            </code>
            <a class="headerlink" href="#torch.backends.cudnn.allow_tf32" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             A
             <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                bool
               </span>
              </code>
             </a>
             that controls where TensorFloat-32 tensor cores may be used in cuDNN
convolutions on Ampere or newer GPUs. See
             <a class="reference internal" href="notes/cuda.html#tf32-on-ampere">
              <span class="std std-ref">
               TensorFloat-32(TF32) on Ampere devices
              </span>
             </a>
             .
            </p>
           </dd>
          </dl>
          <dl class="py attribute">
           <dt id="torch.backends.cudnn.deterministic">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cudnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              deterministic
             </span>
            </code>
            <a class="headerlink" href="#torch.backends.cudnn.deterministic" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             A
             <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                bool
               </span>
              </code>
             </a>
             that, if True, causes cuDNN to only use deterministic convolution algorithms.
See also
             <a class="reference internal" href="generated/torch.are_deterministic_algorithms_enabled.html#torch.are_deterministic_algorithms_enabled" title="torch.are_deterministic_algorithms_enabled">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.are_deterministic_algorithms_enabled()
               </span>
              </code>
             </a>
             and
             <a class="reference internal" href="generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms" title="torch.use_deterministic_algorithms">
              <code class="xref py py-func docutils literal notranslate">
               <span class="pre">
                torch.use_deterministic_algorithms()
               </span>
              </code>
             </a>
             .
            </p>
           </dd>
          </dl>
          <dl class="py attribute">
           <dt id="torch.backends.cudnn.benchmark">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.cudnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              benchmark
             </span>
            </code>
            <a class="headerlink" href="#torch.backends.cudnn.benchmark" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             A
             <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)">
              <code class="xref py py-class docutils literal notranslate">
               <span class="pre">
                bool
               </span>
              </code>
             </a>
             that, if True, causes cuDNN to benchmark multiple convolution algorithms
and select the fastest.
            </p>
           </dd>
          </dl>
         </div>
         <div class="section" id="torch-backends-mkl">
          <h2>
           torch.backends.mkl
           <a class="headerlink" href="#torch-backends-mkl" title="Permalink to this headline">
            ¶
           </a>
          </h2>
          <dl class="py function">
           <dt id="torch.backends.mkl.is_available">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.mkl.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              is_available
             </span>
            </code>
            <span class="sig-paren">
             (
            </span>
            <span class="sig-paren">
             )
            </span>
            <a class="reference internal" href="_modules/torch/backends/mkl.html#is_available">
             <span class="viewcode-link">
              <span class="pre">
               [source]
              </span>
             </span>
            </a>
            <a class="headerlink" href="#torch.backends.mkl.is_available" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             Returns whether PyTorch is built with MKL support.
            </p>
           </dd>
          </dl>
         </div>
         <div class="section" id="torch-backends-mkldnn">
          <h2>
           torch.backends.mkldnn
           <a class="headerlink" href="#torch-backends-mkldnn" title="Permalink to this headline">
            ¶
           </a>
          </h2>
          <dl class="py function">
           <dt id="torch.backends.mkldnn.is_available">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.mkldnn.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              is_available
             </span>
            </code>
            <span class="sig-paren">
             (
            </span>
            <span class="sig-paren">
             )
            </span>
            <a class="reference internal" href="_modules/torch/backends/mkldnn.html#is_available">
             <span class="viewcode-link">
              <span class="pre">
               [source]
              </span>
             </span>
            </a>
            <a class="headerlink" href="#torch.backends.mkldnn.is_available" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             Returns whether PyTorch is built with MKL-DNN support.
            </p>
           </dd>
          </dl>
         </div>
         <div class="section" id="torch-backends-openmp">
          <h2>
           torch.backends.openmp
           <a class="headerlink" href="#torch-backends-openmp" title="Permalink to this headline">
            ¶
           </a>
          </h2>
          <dl class="py function">
           <dt id="torch.backends.openmp.is_available">
            <code class="sig-prename descclassname">
             <span class="pre">
              torch.backends.openmp.
             </span>
            </code>
            <code class="sig-name descname">
             <span class="pre">
              is_available
             </span>
            </code>
            <span class="sig-paren">
             (
            </span>
            <span class="sig-paren">
             )
            </span>
            <a class="reference internal" href="_modules/torch/backends/openmp.html#is_available">
             <span class="viewcode-link">
              <span class="pre">
               [source]
              </span>
             </span>
            </a>
            <a class="headerlink" href="#torch.backends.openmp.is_available" title="Permalink to this definition">
             ¶
            </a>
           </dt>
           <dd>
            <p>
             Returns whether PyTorch is built with OpenMP support.
            </p>
           </dd>
          </dl>
         </div>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>