<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.utils.mobile_optimizer — PyTorch 1.12 documentation
  </title>
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <!-- Google Analytics -->
  <!-- End Google Analytics -->
  <!-- Preload the theme fonts -->
  <!-- Preload the katex fonts -->
 </head>
 <body class="pytorch-body">
  <div class="pytorch-container">
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <div class="section" id="torch-utils-mobile-optimizer">
         <h1>
          torch.utils.mobile_optimizer
          <a class="headerlink" href="#torch-utils-mobile-optimizer" title="Permalink to this headline">
           ¶
          </a>
         </h1>
         <div class="admonition warning">
          <p class="admonition-title">
           Warning
          </p>
          <p>
           This API is in beta and may change in the near future.
          </p>
         </div>
         <p>
          Torch mobile supports
          <code class="docutils literal notranslate">
           <span class="pre">
            torch.mobile_optimizer.optimize_for_mobile
           </span>
          </code>
          utility to run a list of optimization pass with modules in eval mode.
The method takes the following parameters: a torch.jit.ScriptModule object, a blocklisting optimization set and a preserved method list
         </p>
         <dl class="simple">
          <dt>
           By default, if optimization blocklist is None or empty,
           <code class="docutils literal notranslate">
            <span class="pre">
             optimize_for_mobile
            </span>
           </code>
           will run the following optimizations:
          </dt>
          <dd>
           <ul class="simple">
            <li>
             <p>
              <strong>
               Conv2D + BatchNorm fusion
              </strong>
              (blocklisting option
              <cite>
               MobileOptimizerType::CONV_BN_FUSION
              </cite>
              ):  This optimization pass folds
              <code class="docutils literal notranslate">
               <span class="pre">
                Conv2d-BatchNorm2d
               </span>
              </code>
              into
              <code class="docutils literal notranslate">
               <span class="pre">
                Conv2d
               </span>
              </code>
              in
              <code class="docutils literal notranslate">
               <span class="pre">
                forward
               </span>
              </code>
              method of this module and all its submodules. The weight and bias of the
              <code class="docutils literal notranslate">
               <span class="pre">
                Conv2d
               </span>
              </code>
              are correspondingly updated.
             </p>
            </li>
            <li>
             <p>
              <strong>
               Insert and Fold prepacked ops
              </strong>
              (blocklisting option
              <cite>
               MobileOptimizerType::INSERT_FOLD_PREPACK_OPS
              </cite>
              ): This optimization pass rewrites the graph to replace 2D convolutions and linear ops with their prepacked counterparts. Prepacked ops are stateful ops in that, they require some state to be created, such as weight prepacking and use this state, i.e. prepacked weights, during op execution. XNNPACK is one such backend that provides prepacked ops, with kernels optimized for mobile platforms (such as ARM CPUs). Prepacking of weight enables efficient memory access and thus faster kernel execution. At the moment
              <code class="docutils literal notranslate">
               <span class="pre">
                optimize_for_mobile
               </span>
              </code>
              pass rewrites the graph to replace
              <code class="docutils literal notranslate">
               <span class="pre">
                Conv2D/Linear
               </span>
              </code>
              with 1) op that pre-packs weight for XNNPACK conv2d/linear ops and 2) op that takes pre-packed weight and activation as input and generates output activations. Since 1 needs to be done only once, we fold the weight pre-packing such that it is done only once at model load time. This pass of the
              <code class="docutils literal notranslate">
               <span class="pre">
                optimize_for_mobile
               </span>
              </code>
              does 1 and 2 and then folds, i.e. removes, weight pre-packing ops.
             </p>
            </li>
            <li>
             <p>
              <strong>
               ReLU/Hardtanh fusion
              </strong>
              : XNNPACK ops support fusion of clamping. That is clamping of output activation is done as part of the kernel, including for 2D convolution and linear op kernels. Thus clamping effectively comes for free. Thus any op that can be expressed as clamping op, such as
              <code class="docutils literal notranslate">
               <span class="pre">
                ReLU
               </span>
              </code>
              or
              <code class="docutils literal notranslate">
               <span class="pre">
                hardtanh
               </span>
              </code>
              , can be fused with previous
              <code class="docutils literal notranslate">
               <span class="pre">
                Conv2D
               </span>
              </code>
              or
              <code class="docutils literal notranslate">
               <span class="pre">
                linear
               </span>
              </code>
              op in XNNPACK. This pass rewrites graph by finding
              <code class="docutils literal notranslate">
               <span class="pre">
                ReLU/hardtanh
               </span>
              </code>
              ops that follow XNNPACK
              <code class="docutils literal notranslate">
               <span class="pre">
                Conv2D/linear
               </span>
              </code>
              ops, written by the previous pass, and fuses them together.
             </p>
            </li>
            <li>
             <p>
              <strong>
               Dropout removal
              </strong>
              (blocklisting option
              <cite>
               MobileOptimizerType::REMOVE_DROPOUT
              </cite>
              ): This optimization pass removes
              <code class="docutils literal notranslate">
               <span class="pre">
                dropout
               </span>
              </code>
              and
              <code class="docutils literal notranslate">
               <span class="pre">
                dropout_
               </span>
              </code>
              nodes from this module when training is false.
             </p>
            </li>
            <li>
             <p>
              <strong>
               Conv packed params hoisting
              </strong>
              (blocklisting option
              <cite>
               MobileOptimizerType::HOIST_CONV_PACKED_PARAMS
              </cite>
              ): This optimization pass moves convolution packed params to the root module, so that the convolution structs can be deleted. This decreases model size without impacting numerics.
             </p>
            </li>
           </ul>
          </dd>
         </dl>
         <p>
          <code class="docutils literal notranslate">
           <span class="pre">
            optimize_for_mobile
           </span>
          </code>
          will also invoke freeze_module pass which only preserves
          <code class="docutils literal notranslate">
           <span class="pre">
            forward
           </span>
          </code>
          method. If you have other method to that needed to be preserved,  add them into the preserved method list and pass into the method.
         </p>
         <dl class="py function">
          <dt id="torch.utils.mobile_optimizer.optimize_for_mobile">
           <code class="sig-prename descclassname">
            <span class="pre">
             torch.utils.mobile_optimizer.
            </span>
           </code>
           <code class="sig-name descname">
            <span class="pre">
             optimize_for_mobile
            </span>
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              script_module
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              optimization_blocklist
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              preserved_methods
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              None
             </span>
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             <span class="pre">
              backend
             </span>
            </span>
            <span class="o">
             <span class="pre">
              =
             </span>
            </span>
            <span class="default_value">
             <span class="pre">
              'CPU'
             </span>
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="reference internal" href="_modules/torch/utils/mobile_optimizer.html#optimize_for_mobile">
            <span class="viewcode-link">
             <span class="pre">
              [source]
             </span>
            </span>
           </a>
           <a class="headerlink" href="#torch.utils.mobile_optimizer.optimize_for_mobile" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 script_module
                </strong>
                – An instance of torch script module with type of ScriptModule.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 optimization_blocklist
                </strong>
                – A set with type of MobileOptimizerType. When set is not passed,
optimization method will run all the optimizer pass; otherwise, optimizer
method will run the optimization pass that is not included inside optimization_blocklist.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 preserved_methods
                </strong>
                – A list of methods that needed to be preserved when freeze_module pass is invoked
               </p>
              </li>
              <li>
               <p>
                <strong>
                 backend
                </strong>
                – Device type to use for running the result model (‘CPU’(default), ‘Vulkan’ or ‘Metal’).
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-even">
             Returns
            </dt>
            <dd class="field-even">
             <p>
              A new optimized torch script module
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
        </div>
       </article>
      </div>
     </div>
    </div>
   </section>
  </div>
 </body>
</html>